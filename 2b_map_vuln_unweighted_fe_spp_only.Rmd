---
title: "Map vulnerability, unweighted, including only FE spp"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/src/templates/ohara_hdr.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(raster)
library(oharac)
library(tidyverse)
library(here)
source(here('common_fxns.R'))

```

# Summary

This script generates an unweighted mean/sd map of species, similar to script 2, but limits the analysis only to the same subset of species used in script 3a, for apples-to-apples comparison of results.

# Data

* AquaMaps and IUCN rangemaps
* Vulnerability Framework data for vulnerability scores
* FishBase/SeaLifeBase and vulnerability framework data for functional entity assignments

# Methods

## Unweighted, by species

Read in AquaMaps and IUCN maps and vulnerability scores.  AquaMaps maps will exclude species with fewer than 10 occurrence cells, and will use a probability threshold of 0.5.  Here, we include the same spp as script 3a (mapped $\cap$ trait-based vulnerability $\cap$ functional entity) except without the functional vulnerability weighting.

Iterating over each stressor, calculate cell-by-cell mean (and standard deviation?).

* At the 10 km Mollweide resolution, rather than HCAF resolution, we will probably have to chunk this out and then add the pieces together.
* Processing by taxonomic group first, then combining.

```{r}
spp_am <- get_am_spp_info()  %>%
  filter(occur_cells >= 10) %>%
  select(species = sciname) %>%
  mutate(am_mapped = TRUE) %>%
  distinct()

spp_iucn <- read_csv(here('_data/iucn_spp/iucn_to_worms_match.csv'), show_col_types = FALSE) %>%
  rename(species = worms_name, iucn_mapped = mapped)

spp_vuln <- get_spp_vuln() %>%
  select(species, stressor, taxon, score)  %>%
  mutate(vuln = TRUE) %>%
  distinct()

spp_worms <- assemble_worms() %>%
  select(species) %>%
  mutate(worms = TRUE) %>%
  distinct()

spp_fe <- read_csv(here('_output/func_entities/fe_species.csv'), show_col_types = FALSE)

all_spp <- spp_worms %>%
  full_join(spp_vuln, by = 'species') %>%
  full_join(spp_am,   by = 'species') %>%
  full_join(spp_iucn, by = 'species') %>%
  full_join(spp_fe,   by = 'species')

spp_for_vuln_calc <- all_spp %>%
  ### names in WoRMS
  filter(worms) %>%
  ### only those spp in vulnerability project?
  filter(vuln) %>%
  ### mapped in AquaMaps and/or IUCN
  filter(am_mapped | iucn_mapped) %>%
  ### and with valid FE classification
  filter(!is.na(fe_id))

### check gapfill inclusion
gf_df <- spp_for_vuln_calc %>% 
  select(species, taxon) %>% 
  distinct() %>% 
  left_join(read_csv(here('../spp_vuln_framework/int/up_down_gf_quality.csv'))) %>%
  group_by(taxon) %>%
  summarize(mean_gapfill = mean(mean_gapfill),
            mean_match   = mean(mean_match))
knitr::kable(gf_df)
```


### Taxon-by-taxon vulnerability maps

Loop over each stressor, then over each taxon.  Generate a mean and sd vulnerability map for each combination; save to Mazu.

```{r vuln by species iterating over stressors and taxa}

strs <- spp_for_vuln_calc$stressor %>% unique() %>% sort()
taxa <- spp_for_vuln_calc$taxon %>% unique() %>% sort()

# spp_for_vuln_calc %>%
#   group_by(taxon) %>%
#   summarize(n_spp = n_distinct(species))

out_stem <- here_anx('vuln_maps/vuln_unweighted_fe_only/vuln_by_str_tx/vuln_tx_%s_%s_%s.tif')
  ### format will be: taxon, stressor, parameter (mean or sd)
### zxcv <- list.files(dirname(out_stem), full.names = TRUE)
### unlink(zxcv)

for(t in taxa) {
  ### t <- taxa[1]
  
  ### check if all taxon-stressor maps are complete
  outf_mean_all_strs <- sprintf(out_stem, t, strs, 'mean')
  outf_sdev_all_strs <- sprintf(out_stem, t, strs, 'sdev')
  if(all(file.exists(outf_mean_all_strs, outf_sdev_all_strs))) {
    message('All stressor rasters exist for taxon ', t, '... skipping!')
    next()
  }
  
  ### Some taxon-stressor maps remain, so continue:
  ### Load species rangemaps for this taxon
  ### identify spp and map sources for this taxon
  spp_map_fstem <- here_anx('spp_maps_mol', '%s_spp_mol_%s.csv')

  tx_spp <- spp_for_vuln_calc %>%
    filter(taxon == t) %>%
    select(species, am_mapped, iucn_mapped, iucn_sid) %>%
    distinct() %>%
    mutate(src = ifelse(iucn_mapped & !is.na(iucn_mapped), 'iucn', 'am'),
           id  = ifelse(src == 'iucn', iucn_sid, str_replace_all(species, ' ', '_')),
           map_f = sprintf(spp_map_fstem, src, id)) %>%
    select(species, src, map_f) %>%
    distinct()
  
  ### load IUCN and AquaMaps maps for this taxon; flatten to presence = 1
  message('Loading ', nrow(tx_spp), ' rangemaps for taxon ', t, '...')
  tx_maps <- parallel::mclapply(tx_spp$map_f, mc.cores = 40, 
                  ### f <- tx_spp$map_f[1]
                  FUN = function(f) {
                    src <- ifelse(str_detect(basename(f), 'iucn_spp_mol'), 'iucn', 'am')
                    df <- data.table::fread(f)
                    if(src == 'iucn') {
                      df <- df %>%
                        filter(presence != 5) %>% 
                        select(-presence)
                    } else {
                      df <- df %>%
                        filter(prob >= .5) %>%
                        select(-prob)
                    }
                    return(df)}) %>%
    setNames(tx_spp$species) %>%
    # bind_rows(.id = 'species') %>%
    data.table::rbindlist(idcol = 'species') %>%
    distinct()
  message('Taxon ', t, ' rangemap dataframe: ', nrow(tx_maps), 
          ' cell observations for ', nrow(tx_spp), ' species...')

  for(s in strs) {
  ### s <- strs[2]
    outf_mean <- sprintf(out_stem, t, s, 'mean')
    outf_sdev <- sprintf(out_stem, t, s, 'sdev')
    outf_nspp <- sprintf(out_stem, t, s, 'nspp')
    if(all(file.exists(outf_mean, outf_sdev, outf_nspp))) {
      message('Rasters exist for taxon ', t, ' for stressor ', s, '... skipping!')
      next()
    }
    ### identify species vulnerability for this stressor
    ### multiply each species map by vulnerability to this stressor
    ### calculate mean and sd per cell
    
    message('Processing mean/sd vulnerability by species in taxon ', t, ' to stressor: ', s)
    tx_spp_str_vuln <- spp_for_vuln_calc %>%
      filter(stressor == s & taxon == t) %>%
      select(species, score) %>%
      distinct()
    
    ### because failures might occur with summarizing a huge dataset,
    ### let's break this into chunks by cell_id - there are 6.6e+06 cells total
    ### note - this is probably really only necessary for fish with 10k+ species
    chunk_size <- 500000
    n_chunks <- ceiling(ncell(raster::raster(here('_spatial/ocean_area_mol.tif'))) / chunk_size)

    ### Set up so number of cores is related to number of cells to combine, 
    ### to avoid memory issues for large taxa (i.e., fish)
    ### for cephs, with 63e6 cells, 14 cores (1 per chunk) worked fine
    n_cores <- floor(n_chunks / ceiling(nrow(tx_maps)/7e7))
    message('   Processing stressor ', s, ' on taxon ', t,
            ' across ', nrow(tx_maps), ' cells; mc.cores = ', n_cores, '...')
    # system.time({
    result_df <- parallel::mclapply(1:n_chunks, mc.cores = n_cores,
                   FUN = function(n) { ### n <- 1
                     cell_id_min <- (n - 1) * chunk_size + 1
                     cell_id_max <- n * chunk_size
                     message('Summarizing stressor ', s, ' on taxon ', t, 
                             ': cells ', cell_id_min, ' - ', cell_id_max, '...')

                     chunk_sum <- tx_maps %>%
                       filter(between(cell_id, cell_id_min, cell_id_max)) %>%
                       oharac::dt_join(tx_spp_str_vuln, by = 'species', type = 'inner') %>%
                       group_by(cell_id) %>%
                       summarize(score_mean = mean(score) %>% round(5),
                                 score_sd   = sd(score) %>% round(5),
                                 n_spp      = n_distinct(species),
                                 .groups = 'drop')
                     }) %>%
      data.table::rbindlist() %>%
      filter(!is.na(cell_id))
    
    rast_mean <- map_to_mol(result_df, which = 'score_mean')
    rast_sd   <- map_to_mol(result_df, which = 'score_sd')
    rast_nspp <- map_to_mol(result_df, which = 'n_spp')
    
  
    writeRaster(rast_mean, outf_mean, overwrite = TRUE)
    writeRaster(rast_sd,   outf_sdev, overwrite = TRUE)
    writeRaster(rast_nspp, outf_nspp, overwrite = TRUE)
  }
}

```

### Aggregate taxon stressor maps to all species

For each stressor, pull in all taxon rasters, assemble into dataframe, and summarize to aggregate mean, sd, and nspp.  This will require a pooled variance approach to backing out the standard deviation.

Pooled variance formula when variances not necessarily equal (from one of the responses [here](https://math.stackexchange.com/questions/2971315/how-do-i-combine-standard-deviations-of-two-groups))

$$s^2_{x_1 \cup x_2} = \frac{(n_1-1)s^2_{x_1} + (n_2-1)s^2_{x_2}}{(n_1+n_2-1)} + 
\frac{n_1 n_2(\bar x_1 - \bar x_2)^2}{(n_1+n_2)(n_1+n_2-1)}$$

But how does this formula work for multiple groups?  Seems like the correction factor gets increasingly complicated, but a sequential calculation, each time taking the result from one combo and combining it with a new set, should work.  Here I define a function for a two-sample pooled variance, and then an iterated version that sequentially pools elements into the larger pool.

```{r pooled var function and test}

pooled_var <- function(x_bar, y_bar, s_x, s_y, n_x, n_y) {
  ### convert std dev to var
  var_x <- ifelse(is.na(s_x), 0, s_x^2)
  var_y <- ifelse(is.na(s_y), 0, s_y^2)

  var_xy_clean <- ((n_x - 1)*var_x + (n_y - 1)*var_y) / (n_x + n_y - 1)
  var_xy_error <- (n_x * n_y) * (x_bar - y_bar)^2 / ((n_x + n_y)*(n_x + n_y - 1))
  
  return(var_xy_clean + var_xy_error)
}

iterated_pooled_var <- function(mean_vec, sdev_vec, n_vec, flag = FALSE) {
  if(!all.equal(length(mean_vec), length(sdev_vec), length(n_vec))) {
    stop('Mean, std dev, and n vectors must all be equal length!')
  }
  if(length(mean_vec) == 1) {
    warning('Only one element - no need for pooled variance!')
    return(sdev_vec[1]^2)
  }
  ### initialize values for first in list
  mean_x <- mean_vec[1]; s_x <- sdev_vec[1]; n_x <- n_vec[1]
  for(i in 2:length(mean_vec)) { ## i <- 2
    if(flag) message('  ... processing iteration ', i - 1, '...')
    
    mean_y <- mean_vec[i]
    s_y    <- sdev_vec[i]
    n_y    <- n_vec[i]
    var_out <- pooled_var(x_bar = mean_x, y_bar = mean_y, 
                          n_x = n_x, n_y = n_y, 
                          s_x = s_x, s_y = s_y)
  
    ### set up values for next iteration
    mean_x <- (mean_x * n_x + mean_y * n_y) / (n_x + n_y)
    s_x <- sqrt(var_out)
    n_x <- n_x + n_y
  }
  return(var_out)
}
### see tests of these in script 2, unweighted vulnerability

```

```{r moar helper fxns}
combine_taxa_maps <- function(str_tx_v_df, stressor) {
  
  mean_fs <- str_tx_v_df %>% filter(p == 'mean') %>% .$f
  sdev_fs <- str_tx_v_df %>% filter(p == 'sdev') %>% .$f
  nspp_fs <- str_tx_v_df %>% filter(p == 'nspp') %>% .$f
  
  message('... loading mean maps across all taxa for stressor ', stressor, '...')
  mean_df <- parallel::mclapply(mean_fs, mc.cores = 24, FUN = r_to_df) %>%
    setNames(taxa) %>%
    data.table::rbindlist(idcol = 'taxon') %>%
    rename(v_mean = val)
  
  message('... loading std dev maps across all taxa for stressor ', stressor, '...')
  sdev_df <- parallel::mclapply(sdev_fs, mc.cores = 24, FUN = r_to_df) %>%
    setNames(taxa) %>%
    data.table::rbindlist(idcol = 'taxon') %>%
    rename(v_sdev = val)
  
  message('... loading nspp maps across all taxa for stressor ', stressor, '...')
  nspp_df <- parallel::mclapply(nspp_fs, mc.cores = 24, FUN = r_to_df) %>%
    setNames(taxa) %>%
    data.table::rbindlist(idcol = 'taxon') %>%
    rename(v_nspp = val)
  
  message('... joining mean, sd, nspp into big-ass dataframe for stressor ', stressor, '...')
  big_df <- mean_df %>%
    oharac::dt_join(sdev_df, by = c('taxon', 'cell_id'), type = 'full') %>%
    oharac::dt_join(nspp_df, by = c('taxon', 'cell_id'), type = 'full')
  
  return(big_df)
}


process_mean_rasts <- function(big_df) {
  ### Set up for parallel processing
  cell_id_vec <- big_df$cell_id %>% unique()
  n_gps <- 25
  gp_vec <- rep(1:n_gps, length.out = length(cell_id_vec))
  
  ### perform parallel processing
  all_spp_mean_list <- parallel::mclapply(
    X = 1:n_gps, mc.cores = 25, 
    FUN = function(gp) { ### gp <- 1
      gp_cells <- cell_id_vec[gp_vec == gp]
      message('...processing ', length(gp_cells), ' cells in group ', gp, '...')
      gp_out <- big_df %>%
        filter(cell_id %in% gp_cells) %>%
        group_by(cell_id) %>%
        summarize(vuln_mean = (sum(v_mean * v_nspp) / sum(v_nspp)) %>% round(5))
    })
  
  ### gather results
  all_spp_mean_df <- data.table::rbindlist(all_spp_mean_list)
  return(all_spp_mean_df)
}

process_sdev_rasts <- function(big_df) {
  ### Set up for parallel processing
  cell_id_vec <- big_df$cell_id %>% unique()
  n_gps <- 100
  gp_vec <- rep(1:n_gps, length.out = length(cell_id_vec))
  
  ### perform parallel processing
  all_spp_sdev_list <- parallel::mclapply(
    X = 1:n_gps, mc.cores = 20, 
    FUN = function(gp) { ### gp <- round(n_gps / 2)
      gp_cells <- cell_id_vec[gp_vec == gp]
      message('...processing ', length(gp_cells), ' cells in group ', gp, ' of ', n_gps, '...')
      # system.time({
        gp_sdev_out <- big_df %>%
          filter(cell_id %in% gp_cells) %>%
          group_by(cell_id) %>%
          summarize(vuln_var = iterated_pooled_var(v_mean, v_sdev, v_nspp),
                    vuln_sdev = sqrt(vuln_var) %>% round(5))
      # })
      return(gp_sdev_out)
    })
  
  ### gather results
  all_spp_sdev <- data.table::rbindlist(all_spp_sdev_list)
  return(all_spp_sdev)
}

r_to_df <- function(f) {
  r <- raster::raster(f)
  df <- data.frame(val = values(r),
                   cell_id = 1:ncell(r)) %>%
    filter(!is.na(val))
  return(df)
}
```

```{r assemble taxon vuln maps to total maps}

tx_v_map_df <- data.frame(f = list.files(dirname(out_stem), full.names = TRUE,
                                         pattern = 'vuln_tx_.+.tif')) %>%
  mutate(t = str_extract(basename(f), paste0(taxa, collapse = '|')),
         s = str_extract(basename(f), paste0(strs, collapse = '|')),
         p = str_extract(basename(f), '_mean|_sdev|_nspp') %>% str_remove('_'))

out_stem <- here('_output/vuln_maps/vuln_maps_unweighted_fe_only/vuln_fe_spp_%s_%s.tif')
  ### format will be: stressor, parameter (mean, sd, nspp)


for(stressor in strs) {
  ### stressor <- strs[1]
  
  ### check if total stressor maps are complete
  outf_mean <- sprintf(out_stem, stressor, 'mean')
  outf_sdev <- sprintf(out_stem, stressor, 'sdev')

  if(all(file.exists(outf_mean, outf_sdev))) {
    message('All rasters exist for stressor ', stressor, '... skipping!')
    next()
  }
  
  ### Combine mean, sdev, and nspp maps by taxon into one big dataframe
  message('Processing mean, sd, nspp maps across FE-only species for ', stressor, ' stressor...')
  str_tx_v_df <- tx_v_map_df %>%
    filter(s == stressor)
  big_df <- combine_taxa_maps(str_tx_v_df, stressor)
    
  ### Process nspp_rast only one time (same across all stressors)
  ### note: this should be redundant with nspp_in_fv_weighted_vuln_maps.tif
  vuln_nspp_rast_f <- here('_output/nspp_maps/nspp_in_unwt_fe_only_vuln_maps.tif')
  if(!file.exists(vuln_nspp_rast_f)) {
    message('... summarizing species richness map across all taxa, FE-spp only...')
    all_spp_nspp <- big_df %>%
      group_by(cell_id) %>%
      summarize(vuln_nspp = sum(v_nspp))
    message('Creating species richness raster for unweighted vuln maps incl. only FE spp...')
    rast_nspp <- map_to_mol(all_spp_nspp, which = 'vuln_nspp')
    writeRaster(rast_nspp, vuln_nspp_rast_f, overwrite = TRUE)
  }
  
  ### Process mean raster across taxa
  if(!file.exists(outf_mean)) {
    message('... summarizing mean vulnerability map across all taxa, FE spp only...')
    ptm <- proc.time()
    
    all_spp_mean <- process_mean_rasts(big_df)
    rast_mean <- map_to_mol(all_spp_mean, which = 'vuln_mean')
  
    message('... elapsed: ', round((proc.time() - ptm)[3], 3), ' seconds.  ', 
            'Writing out mean raster: \n  ',
            str_replace(outf_mean, '/home/ohara/github/', 'GitHub:'))
  
    writeRaster(rast_mean, outf_mean, overwrite = TRUE)
  }
  
  ### Process standard deviation raster across taxa using pooled var
  if(!file.exists(outf_sdev)) {
    message('... summarizing std dev vuln map across all taxa, FE spp only...')
    ### break this into smaller chunks and parallelize over those?
    ptm <- proc.time()

    all_spp_sdev <- process_sdev_rasts(big_df)
    rast_sdev <- map_to_mol(all_spp_sdev, which = 'vuln_sdev')
    
    message('... elapsed: ', round((proc.time() - ptm)[3], 3), ' seconds.  ',
            'Writing out std dev raster: \n  ',
            str_replace(outf_sdev, '/home/ohara/github/', 'GitHub:'))
    
    writeRaster(rast_sdev, outf_sdev, overwrite = TRUE)
  }
}

```


## Plot example maps

```{r plot vuln by stressor, fig.height = 4, fig.width = 7}

vuln_fe_spp_dir <- here('_output/vuln_maps/vuln_maps_unweighted_fe_only')
mean_fs <- list.files(vuln_fe_spp_dir, pattern = '_mean.tif', full.names = TRUE)
sdev_fs <- list.files(vuln_fe_spp_dir, pattern = '_sdev.tif', full.names = TRUE)

focal_strs <- c('biomass_removal', 'bycatch', 
                'microplastic', 'wildlife_strike',
                'nutrient_pollution', 'ocean_acidification', 
                'sst_rise', 'marine_heat_wave',
                'light_pollution')

for(f in focal_strs) { ### f <- focal_strs[1]
  mean_f <- mean_fs[str_detect(basename(mean_fs), f)]
  sdev_f <- sdev_fs[str_detect(basename(sdev_fs), f)]
  mean_rast <- raster::raster(mean_f)
  sdev_rast <- raster::raster(sdev_f)
  cv_rast <- sdev_rast / mean_rast
  
  map_cols <- hcl.colors(n = 50)
  
  plot(mean_rast, zlim = c(0, 1), col = map_cols, main = paste0('Mean vuln, FE spp only: ', f),
       legend = FALSE, axes = FALSE)  
  plot(cv_rast, col = map_cols, main = paste0('Coef of Var vuln: ', f),
       legend = TRUE, axes = FALSE)
}
```
