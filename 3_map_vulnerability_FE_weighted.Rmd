---
title: "Map vulnerability - weighted by functional vulnerability"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/src/templates/ohara_hdr.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(raster)
library(oharac)
library(tidyverse)
library(here)
source(here('common_fxns.R'))

```

# Summary

Apply vulnerability scores to mapped species.  Map out vulnerability to each stressor, first unweighted by species (each spp counts same, see script 2), then weighted by functional vulnerability (FEs with higher FV are given greater weight, this script).

# Data

* AquaMaps and IUCN rangemaps
* Vulnerability Framework data for vulnerability scores
* FishBase/SeaLifeBase and vulnerability framework data for functional entity assignments

# Methods

## Functional vulnerability weighted

Read in AquaMaps and IUCN maps and vulnerability scores.  AquaMaps maps will exclude species with fewer than 10 occurrence cells, and will use a probability threshold of 0.5.  Here, we can include all species in the intersection of (mapped $\cap$ trait-based vulnerability) without worrying about functional entity membership.

To calculate functional vulnerability of species within a cell, we must know all species in that cell (and their FE membership).  But loading in all spp maps simultaneously will likely be too memory intensive.  Because of the number of cells and species, we will break the map into chunks of e.g., 100,000 cells at a time.  For each chunk, we will read in each species map, filtering to the chunk cells only to keep the memory needs down, bind the lookup of species-to-functional entity, calculate functional vulnerability for each FE for each cell.  Then, iterating over each stressor, for that chunk, calculate FV-weighted mean and sd vulnerability (as well as total FV weight value).  Save all chunk data as temp files, then combine per stressor.

```{r}
spp_am <- get_am_spp_info()  %>%
  filter(occur_cells >= 10) %>%
  select(species = sciname) %>%
  mutate(am_mapped = TRUE) %>%
  distinct()

spp_iucn <- read_csv(here('_data/iucn_spp/iucn_to_worms_match.csv'), show_col_types = FALSE) %>%
  rename(species = worms_name, iucn_mapped = mapped)

spp_vuln <- get_spp_vuln(gapfill = 'family') %>%
  select(species, stressor, taxon, score, sd_score)  %>%
  mutate(vuln = TRUE) %>%
  distinct()

spp_worms <- assemble_worms() %>%
  select(species) %>%
  mutate(worms = TRUE) %>%
  distinct()

spp_fe <- read_csv(here('_output/func_entities/fe_species.csv'), show_col_types = FALSE)

all_spp <- spp_worms %>%
  full_join(spp_vuln, by = 'species') %>%
  full_join(spp_am,   by = 'species') %>%
  full_join(spp_iucn, by = 'species') %>%
  full_join(spp_fe,   by = 'species')

spp_for_vuln_calc <- all_spp %>%
  ### names in WoRMS
  filter(worms) %>%
  ### only those spp in vulnerability project?
  filter(vuln) %>%
  ### mapped in AquaMaps and/or IUCN
  filter(am_mapped | iucn_mapped) %>%
  ### and with valid FE classification
  filter(!is.na(fe_id))

```

Because of need to overlap species with range maps, vulnerability scores, and functional entity membership, this analysis includes `r spp_for_vuln_calc$species %>% n_distinct()` species.

### Temporary cell cluster FE-weighted vulnerability maps

Functional vulnerability for a functional entity will be calculated based on the number of species $N_{spp}$ in the FE:

$$FV_{FE} = \frac{1}{2^{N_{spp}-1}}$$
The formulation by Sebastien Villeger calculates $FV$ as the proportion of FEs represented by only a single species.  This new formulation accounts for vulnerability of FEs with low membership, and quickly drops off as membership increases - e.g., an FE with two members is given FV of 0.5, while an FE with ten members is given FV of 0.002. 

Overall functional vulnerability of a cell will be the average of FV across all $N_{FE}$ FEs in the cell:
$$FV = \frac{\sum FV_{FE}}{N_{FE}}$$

Using the Villeger metric ($FV_i \in \{0, 1\}$) this simplifies to the proportion of FEs represented by a single species.

Then, the FV-weighted mean vulnerability $V_{FV}^{s,i}$ of a functional entity $i$ to a stressor $s$ is calculated as the average stressor vulnerability $v_s$ of all spp $j \in 1:N_{spp,i}$in that FE, times the functional vulnerability:
$$V_{FV}^{s,i} = FV_i \times \frac{1}{N_{spp,i}}\sum_{j=1}^{N_{spp,i}} v_{s,j} = FV_i \times \bar v_s$$
Using the Villeger metric ($FV_i \in \{0, 1\}$), $V_{FV}^{s,i}$ is zero for FEs with $N_{spp,i} > 1$ and equal to $v_{s,1}$ for FEs with $N_{spp,i} = 1$.

The cell overall FV-weighted mean vulnerability to stressor $s$ is:
$$V_{FV}^{s} = \frac{1}{\sum_{k=1}^{N_{FE}} FV_k} \sum_{i=1}^{N_{FE}} FV_i \times \bar v_s = \frac{1}{\sum_{k=1}^{N_{FE}} FV_k} \sum_{i=1}^{N_{FE}} V_{FV}^{s,i}$$

#### Note on mean and sd:

When working with unweighted vulnerabilities (with species counts) we could take a pooled variance approach to determining the standard deviation of vulnerability across all species present in a cell.  Here, the unit of analysis is a functional entity, and weighted not by the number of species in each FE but rather by the functional vulnerability of that FE.  A weighted pooled variance may be possible, but here we will simply report the FV-weighted mean across all FEs in the cell, and standard deviation of FV-weighted mean across all FEs.  This loses information on variance of vulnerability within each FE but that may not be that interesting or critical.

#### Tidy the loop

Because this is a complex process, let's tidy the big `for` loop by breaking out key code as functions.

* `read_truncated_rangemap`: read in all range maps, truncating each one to just those cells in the current chunk.
* `calc_fv`: Calculate the functional vulnerability for a given functional entity based on the number of spp present.
* `calc_spp_cell_fv`: For each cell, identify all FEs and calculate the FV of each.  Because grouping by large numbers of groups (e.g, 100000 cells and multiple FEs), for crash-avoidance, this is parallelized. 
* `bind_maps_list`: for a list of truncated species maps, clean out NULL results and bind rows, keeping cell ID and species name.
* `calc_chunk_str_sum`: for a dataframe of truncated species maps

```{r helper functions}
read_truncated_rangemap <- function(f, chunk_start, chunk_end) {
  ### Identify the source from filename (for filtering by presence or prob)
  src <- ifelse(str_detect(basename(f), 'iucn_spp_mol'), 'iucn', 'am')
  df <- data.table::fread(f) %>%
    filter(between(cell_id, chunk_start, chunk_end)) %>%
    mutate(map_f = f)
  if(src == 'iucn') {
    df <- df %>%
      filter(presence != 5) %>% 
      select(-presence)
  } else {
    df <- df %>%
      filter(prob >= .5) %>%
      select(-prob)
  }
  if(nrow(df) == 0) return(NULL) else return(df)
}

bind_maps_list <- function(chunk_maps_list, spp_map_fs) {
  ### NOTE: for some reason, the bind_rows() in here sometimes causes
  ### unrecoverable errors when knitting, but seems OK when running chunks
  ### individually... try subbing with data.table::rbindlist 
  chunk_maps_raw <- chunk_maps_list %>%
    ### drop NULL instances (no spp cells - helps keep things from crashing)
    purrr::compact() %>% 
    data.table::rbindlist() %>%
    oharac::dt_join(spp_map_fs, by = 'map_f', type = 'left') %>%
    select(-map_f, -src) %>%
    distinct()
  return(chunk_maps_raw)
}

calc_chunk_str_sum <- function(chunk_maps, spp_for_vuln_calc, str) {
  chunk_spp_for_vuln_calc <- spp_for_vuln_calc %>%
    filter(stressor == str) %>%
    filter(species %in% chunk_maps$species) %>%
    select(species, score, sd_score) %>%
    distinct()
  
  cell_id_df <- data.frame(cell_id = chunk_maps$cell_id %>% unique()) %>%
    mutate(cell_gp = rep(1:100, length.out = n()))
  cell_gps <- cell_id_df$cell_gp %>% unique()

  chunk_spp_str_vuln <- chunk_maps %>%
    oharac::dt_join(chunk_spp_for_vuln_calc, by = 'species', type = 'inner') 
  
  ### parallelize for speed! balance vectorization with parallel to reduce crashing...
  chunk_str_vuln_list <- parallel::mclapply(cell_gps, mc.cores = 30,
          FUN = function(gp) {
            cell_ids <- cell_id_df %>% 
              filter(cell_gp == gp) %>% 
              .$cell_id
            df <- chunk_spp_str_vuln %>%
              filter(cell_id %in% cell_ids) %>%
              group_by(cell_id, fe_id) %>%
              summarize(score_mean = mean(score) %>% round(5),
                        score_sd   = sd(score) %>% round(5),
                        n_spp      = n_distinct(species),
                        fv = first(fv),
                        .groups = 'drop') %>%
              group_by(cell_id) %>%
              summarize(n_spp = sum(n_spp),
                        fv_wt_mean_vuln = Hmisc::wtd.mean(score_mean, weights = fv),
                        fv_wt_sd_vuln   = sqrt(Hmisc::wtd.var(score_mean, weights = fv)))
          })
  chunk_str_sum_df <- data.table::rbindlist(chunk_str_vuln_list)
  return(chunk_str_sum_df)
}

calc_fv <- function(n_spp) {
  k <- n_spp - 1
  fv <- 0.5^k
} 

calc_spp_cell_fv <- function(chunk_maps_raw, spp_fe) {
  ### parallelize this mf to keep group_by from crashing everything - but not
  ### for every cell individually!  Set up 1000 different cell groups across 
  ### the 100k(ish) cells - divide work between dplyr and parallel...
  cell_id_df <- data.frame(cell_id = chunk_maps_raw$cell_id %>% unique()) %>%
    mutate(cell_gp = rep(1:100, length.out = n()))
  cell_gps <- cell_id_df$cell_gp %>% unique()
  
  fe_df <- chunk_maps_raw %>%
    left_join(spp_fe %>% select(species, fe_id), by = 'species')
  fv_list <- parallel::mclapply(cell_gps, mc.cores = 30,
                                FUN = function(gp) { 
                                  ### gp <- cell_gps[1]
                                  cell_ids <- cell_id_df %>% 
                                    filter(cell_gp == gp) %>% 
                                    .$cell_id
                                  x <- fe_df %>%
                                    filter(cell_id %in% cell_ids) %>%
                                    mutate(n_spp = n_distinct(species),
                                           n_fes = n_distinct(fe_id)) %>%
                                    group_by(fe_id) %>%
                                    mutate(n_spp_fe = n_distinct(species),
                                           fv = calc_fv(n_distinct(species))) %>%
                                    ungroup()
                                  return(x)
                                })
  fv_df <- data.table::rbindlist(fv_list)
  return(fv_df)
}
```

```{r vuln by species iterating over stressors and chunks of cells}

spp_map_fstem <- here_anx('spp_maps_mol', '%s_spp_mol_%s.csv')
spp_map_fs <- spp_for_vuln_calc %>%
  select(species, am_mapped, iucn_mapped, iucn_sid) %>%
  distinct() %>%
  mutate(src = ifelse(iucn_mapped & !is.na(iucn_mapped), 'iucn', 'am'),
         id  = ifelse(src == 'iucn', iucn_sid, str_replace_all(species, ' ', '_')),
         map_f = sprintf(spp_map_fstem, src, id)) %>%
  select(species, src, map_f) %>%
  distinct()
  
n_cells <- ncell(raster(here('_spatial/ocean_area_mol.tif')))
chunk_size <- 100000
n_chunks <- ceiling(n_cells / chunk_size)

strs <- spp_for_vuln_calc$stressor %>% unique() %>% sort()

out_stem <- here('tmp/vuln_fe_wt_chunks/vuln_summary_chunk_%s_to_%s_%s.csv')
  ### format will be: chunk start, chunk end, stressor

for(chunk_i in 1:n_chunks) { ### chunk_i <- 42
  
  ### Set up chunk start and end and filenames; check whether maps 
  ### all stressors for this chunk...
  chunk_start <- (chunk_i - 1) * chunk_size + 1
  chunk_end   <- as.integer(chunk_i * chunk_size)
  chunk_text <- sprintf('chunk %s of %s (cells %s to %s)', chunk_i, n_chunks, chunk_start, chunk_end)

  ### check if all chunk-stressor maps are complete
  outf_all_strs <- sprintf(out_stem, chunk_start, chunk_end, strs)
  if(all(file.exists(outf_all_strs))) {
    message('All stressor summaries exist for ', chunk_text, '... skipping!')
    next()
  }
  
  ### Some chunk maps remain, so continue:
  ### Load species rangemaps for this chunk, then clean and bind:
  message('Loading ', nrow(spp_map_fs), ' rangemaps cropped for ', chunk_text,  '...')
  
  chunk_maps_list <- parallel::mclapply(spp_map_fs$map_f, mc.cores = 30, 
                                        ### f <- spp_map_fs$map_f[1]
                                        FUN = read_truncated_rangemap, 
                                        chunk_start = chunk_start, chunk_end = chunk_end) 
  
  chunk_maps_raw <- bind_maps_list(chunk_maps_list, spp_map_fs)
  
  ### if result includes no cells, write out empty chunk files
  if(nrow(chunk_maps_raw) == 0) {
    message('No species X cells found for ', chunk_text, '... skipping to next chunk!')
    lapply(outf_all_strs, FUN = function(x) write_csv(data.frame(cell_id = -1), x))
    next()
  }

  ### OK, now we have species and cells for this chunk.  Calculate functional vulnerability!
  message('Calculating functional vulnerability metrics for ', chunk_text, '...')
  chunk_maps <- chunk_maps_raw %>%
    calc_spp_cell_fv(spp_fe)
  
  message('In ', chunk_text,  ' rangemap dataframe: \n    ', nrow(chunk_maps), 
          ' cell observations for ', n_distinct(chunk_maps$species), ' species across ',
          n_distinct(chunk_maps$fe_id), ' functional entities...')
  
  ### For this chunk, loop over all stressors, summarize FV-weighted mean and sd
  for(s in strs) {
    ### s <- strs[2]
    outf_this_str <- sprintf(out_stem, chunk_start, chunk_end, s)
    if(file.exists(outf_this_str)) {
      message('Temp csv exists for ', chunk_text, ' for stressor ', s, '... skipping!')
      next()
    }

    message('Processing mean/sd vuln in ', chunk_text, ' to stressor: ', s)
    chunk_str_sum <- calc_chunk_str_sum(chunk_maps, spp_for_vuln_calc, str = s)
    
    write_csv(chunk_str_sum, outf_this_str)
  }
}

stop()
```

### Aggregate taxon stressor maps to all species

For each stressor, pull in all taxon rasters, assemble into dataframe, and summarize to aggregate mean, sd, and nspp.  This will require a pooled variance approach to backing out the standard deviation.

Pooled variance formula when variances not necessarily equal (from one of the responses [here](https://math.stackexchange.com/questions/2971315/how-do-i-combine-standard-deviations-of-two-groups))

$$s^2_{x_1 \cup x_2} = \frac{(n_1-1)s^2_{x_1} + (n_2-1)s^2_{x_2}}{(n_1+n_2-1)} + 
\frac{n_1 n_2(\bar x_1 - \bar x_2)^2}{(n_1+n_2)(n_1+n_2-1)}$$

But how does this formula work for multiple groups?  Seems like the correction factor gets increasingly complicated, but a sequential calculation, each time taking the result from one combo and combining it with a new set, should work.  Here I define a function for a two-sample pooled variance, and then an iterated version that sequentially pools elements into the larger pool.

```{r pooled var function and test}

pooled_var <- function(x_bar, y_bar, s_x, s_y, n_x, n_y) {
  ### convert std dev to var
  var_x <- ifelse(is.na(s_x), 0, s_x^2)
  var_y <- ifelse(is.na(s_y), 0, s_y^2)

  var_xy_clean <- ((n_x - 1)*var_x + (n_y - 1)*var_y) / (n_x + n_y - 1)
  var_xy_error <- (n_x * n_y) * (x_bar - y_bar)^2 / ((n_x + n_y)*(n_x + n_y - 1))
  
  return(var_xy_clean + var_xy_error)
}

iterated_pooled_var <- function(mean_vec, sdev_vec, n_vec) {
  if(!all.equal(length(mean_vec), length(sdev_vec), length(n_vec))) {
    stop('Mean, std dev, and n vectors must all be equal length!')
  }
  if(length(mean_vec) == 1) {
    warning('Only one element - no need for pooled variance!')
    return(sdev_vec[1]^2)
  }
  ### initialize values for first in list
  mean_x <- mean_vec[1]; s_x <- sdev_vec[1]; n_x <- n_vec[1]
  for(i in 2:length(mean_vec)) { ## i <- 2
    mean_y <- mean_vec[i]
    s_y    <- sdev_vec[i]
    n_y    <- n_vec[i]
    var_out <- pooled_var(x_bar = mean_x, y_bar = mean_y, n_x = n_x, n_y = n_y, s_x = s_x, s_y = s_y)
  
    ### set up values for next iteration
    mean_x <- (mean_x * n_x + mean_y * n_y) / (n_x + n_y)
    s_x <- sqrt(var_out)
    n_x <- n_x + n_y
  }
  return(var_out)
}

### test that the function returns the correct variance value
# set.seed(42)
# n_vec <- c(1, 5, 10, 15)
# x_list <- list(rnorm(mean = 10, sd = 2, n = n_vec[1]),
#                rnorm(mean = 15, sd = 1, n = n_vec[2]),
#                rnorm(mean = 20, sd = 3, n = n_vec[3]),
#                rnorm(mean =  5, sd = 1, n = n_vec[4]))
# 
# ### initialize values for first term
# mean_vec <- sapply(x_list, mean)
# sdev_vec <- sapply(x_list, sd)
# n_vec    <- sapply(x_list, length)
# 
# var_out <- iterated_pooled_var(mean_vec, sdev_vec, n_vec)
# 
# var_check <- var(unlist(x_list))
# 
# var_check == var_out

```

```{r assemble taxon vuln maps to total maps}

tx_v_map_df <- data.frame(f = list.files(dirname(out_stem), full.names = TRUE,
                                         pattern = 'vuln_tx_.+.tif')) %>%
  mutate(t = str_extract(basename(f), paste0(taxa, collapse = '|')),
         s = str_extract(basename(f), paste0(strs, collapse = '|')),
         p = str_extract(basename(f), '_mean|_sdev|_nspp') %>% str_remove('_'))

r_to_df <- function(f) {
  r <- raster::raster(f)
  df <- data.frame(val = values(r),
                   cell_id = 1:ncell(r)) %>%
    filter(!is.na(val))
  return(df)
}

out_stem <- here_anx('vuln_maps/vuln_total/vuln_all_spp_by_str/vuln_all_spp_%s_%s.tif')
  ### format will be: stressor, parameter (mean, sd, nspp)

for(stressor in strs) {
  ### stressor <- strs[1]
  
  ### check if total stressor maps are complete
  outf_mean <- sprintf(out_stem, stressor, 'mean')
  outf_sdev <- sprintf(out_stem, stressor, 'sdev')
  outf_nspp <- sprintf(out_stem, stressor, 'nspp')
  
  if(all(file.exists(outf_mean, outf_sdev, outf_nspp))) {
    message('All rasters exist for stressor ', stressor, '... skipping!')
    next()
  }

  message('Processing mean, sd, nspp maps across all species for ', stressor, ' stressor...')
  str_tx_v_df <- tx_v_map_df %>%
    filter(s == stressor)
  mean_fs <- str_tx_v_df %>% filter(p == 'mean') %>% .$f
  sdev_fs <- str_tx_v_df %>% filter(p == 'sdev') %>% .$f
  nspp_fs <- str_tx_v_df %>% filter(p == 'nspp') %>% .$f
  
  message('... loading mean, sd, nspp maps for all taxa...')
  mean_df <- parallel::mclapply(mean_fs, mc.cores = 12, FUN = r_to_df) %>%
    setNames(taxa) %>%
    data.table::rbindlist(idcol = 'taxon') %>%
    rename(v_mean = val)
  sdev_df <- parallel::mclapply(sdev_fs, mc.cores = 12, FUN = r_to_df) %>%
    setNames(taxa) %>%
    data.table::rbindlist(idcol = 'taxon') %>%
    rename(v_sdev = val)
  nspp_df <- parallel::mclapply(nspp_fs, mc.cores = 12, FUN = r_to_df) %>%
    setNames(taxa) %>%
    data.table::rbindlist(idcol = 'taxon') %>%
    rename(v_nspp = val)
  big_df <- mean_df %>%
    oharac::dt_join(sdev_df, by = c('taxon', 'cell_id'), type = 'full') %>%
    oharac::dt_join(nspp_df, by = c('taxon', 'cell_id'), type = 'full')
    
  message('... summarizing mean vulnerability map across all taxa...')
  all_spp_mean <- big_df %>%
    group_by(cell_id) %>%
    summarize(vuln_mean = sum(v_mean * v_nspp) / sum(v_nspp))
  message('... summarizing species richness map across all taxa...')
  all_spp_nspp <- big_df %>%
    group_by(cell_id) %>%
    summarize(vuln_nspp = sum(v_nspp))
  message('... summarizing standard deviation vulnerability map across all taxa...')
  system.time({
    ### how to speed this one up?
    all_spp_sdev <- big_df %>%
      group_by(cell_id) %>%
      summarize(vuln_sdev = sqrt(iterated_pooled_var(v_mean, v_sdev, v_nspp)))
  })
  
  message('... converting dataframes to rasters...')

  rast_mean <- map_to_mol(all_spp_mean, which = 'vuln_mean')
  rast_sd   <- map_to_mol(all_spp_sdev, which = 'vuln_sdev')
  rast_nspp <- map_to_mol(all_spp_nspp, which = 'vuln_nspp')
  
  message('... writing out rasters: ', 
          '\n    ', str_replace(outf_mean, '/home/shares/ohi/spp_vuln/', 'Mazu:'), 
          '\n    ', str_replace(outf_sdev, '/home/shares/ohi/spp_vuln/', 'Mazu:'), 
          '\n    ', str_replace(outf_nspp, '/home/shares/ohi/spp_vuln/', 'Mazu:'))

  writeRaster(rast_mean, outf_mean, overwrite = TRUE)
  writeRaster(rast_sd,   outf_sdev, overwrite = TRUE)
  writeRaster(rast_nspp, outf_nspp, overwrite = TRUE)
}

```


### FIX ALL THIS

```{r plot vuln by species by stressor, fig.height = 4, fig.width = 10}
focal_strs <- c('biomass', 'bycatch', 'plastic', 
                'nutrient', 'oa', 'water_temp',
                'light', 'noise', 'organic') %>%
  paste0(collapse = '|')
mean_fs <- list.files(here('_output/vuln_by_spp'), pattern = 'mean', full.names = TRUE)
# sd_fs   <- list.files(here('_output/vuln_by_spp'), pattern = 'sd', full.names = TRUE)

mean_fs <- mean_fs[str_detect(basename(mean_fs), focal_strs)]

mean_stack <- raster::stack(mean_fs) %>%
  setNames(str_remove(names(.), 'vuln_by_spp_'))
# sd_stack   <- raster::stack(sd_fs) %>%
#   setNames(str_remove(names(.), 'vuln_by_spp_'))

map_cols <- hcl.colors(n = 10)

plot(mean_stack, zlim = c(0, 1), col = map_cols,
     legend = FALSE, axes = FALSE)
# plot(sd_stack,   zlim = c(0, 1), legend = FALSE, axes = FALSE)
```

### By FE, unweighted

```{r vuln by FE iterating over stressors}

strs <- spp_vuln$stressor %>% unique() %>% sort()

out_stem <- here('_output/vuln_by_fe/vuln_by_fe_%s_%s.tif')
### unlink(list.files(here('_output/vuln_by_fe'), full.names = TRUE))

fe_df <- read_csv(here('_output/func_entities/species_fe.csv'))

am_vuln_fe <- am_vuln %>%
  oharac::dt_join(fe_df, by = 'species', type = 'inner') %>%
  select(am_sid, fe_id, stressor, score) %>%
  distinct()

for(s in strs) {
  ### s <- strs[1]
  if(file.exists(sprintf(out_stem, s, 'mean'))) {
    message('Rasters exist for stressor ', s, '... skipping!')
    next()
  }
  message('processing mean/sd vulnerability by species to stressor: ', s)
  
  am_vuln_str <- am_vuln_fe %>%
    filter(stressor == s)
  
  am_spp_vuln_cells <- am_spp_cells %>%
    oharac::dt_join(am_vuln_str, by = 'am_sid', type = 'inner')
  message('summarizing by FE in each cell...')
  result_df <- am_spp_vuln_cells %>%
    filter(!is.na(score)) %>%
    group_by(loiczid, fe_id) %>%
    ### first, summarize by FE per cell...
    summarize(score_mean1 = mean(score),
              # score_sd   = sd(score),
              .groups = 'drop')
  
  message('...then summarizing across all FEs in each cell...')
  result_df <- result_df %>%
    group_by(loiczid) %>%
    ### ... then average across all FEs
    summarize(score_mean = mean(score_mean1),
              # score_sd   = sqrt(sum(score_sd^2, na.rm = TRUE) / n()),
              # score_sd   = sd(score_mean1), ### this is deviation of mean among FEs
              .groups = 'drop')
    
  rast_mean <- map_to_hcaf(result_df, which = 'score_mean')
  # rast_sd   <- map_to_hcaf(result_df, which = 'score_sd')

  writeRaster(rast_mean, sprintf(out_stem, s, 'mean'), overwrite = TRUE)
  # writeRaster(rast_sd,   sprintf(out_stem, s, 'sd'), overwrite = TRUE)
}
```

#### Inclusion of species: vuln X am X fe

When applying vulnerability scores at the functional entity level, species must be accounted for in AquaMaps, vulnerability scores, and functional entity traits.  In this case, the number of included species is `r am_vuln_fe$am_sid %>% n_distinct()`.  Looking at the intersection of AquaMaps and functional traits only, we include `r fe_df %>% filter(species %in% am_spp_ids$sciname) %>% .$species %>% n_distinct()`.

```{r plot vuln by FE by stressor, fig.height = 4, fig.width = 10}
mean_fs <- list.files(here('_output/vuln_by_fe'), pattern = 'mean', full.names = TRUE)
# sd_fs   <- list.files(here('_output/vuln_by_fe'), pattern = 'sd', full.names = TRUE)

mean_fs <- mean_fs[str_detect(basename(mean_fs), focal_strs)]

mean_stack <- raster::stack(mean_fs) %>%
  setNames(str_remove(names(.), 'vuln_by_fe_'))
# sd_stack   <- raster::stack(sd_fs) %>%
#   setNames(str_remove(names(.), 'vuln_by_fe_'))

plot(mean_stack, zlim = c(0, 1), col = map_cols,
     legend = FALSE, axes = FALSE)
# plot(sd_stack,   zlim = c(0, 1), legend = FALSE, axes = FALSE)
```

### By FE, FV-weighted

Here, calculate mean stressor vulnerability for each functional entity, along with the functional vulnerability of each entity using $\left(\frac{1}{2}\right)^{n-1}$ (so for an FE represented by one species, functional vuln = $\left(\frac{1}{2}\right)^{0}$ 1; for an FE represented by 5 spp, $\left(\frac{1}{2}\right)^{4}$ = .0625; for an FE represented by 10 spp, $\left(\frac{1}{2}\right)^{9}$ = .002 etc).

```{r weighted vuln by FE iterating over stressors}

strs <- spp_vuln$stressor %>% unique() %>% sort()

message('Calculating functional vulnerability by FE and cell...')

out_stem <- here('_output/vuln_by_fe_weighted/vuln_wt_by_fe_%s_%s.tif')

### unlink(list.files(here('_output/vuln_by_fe_weighted'), full.names = TRUE))

for(s in strs) {
  ### s <- strs[2]
  if(file.exists(sprintf(out_stem, s, 'mean'))) {
    message('Rasters exist for stressor ', s, '... skipping!')
    next()
  }

  message('processing mean/sd vulnerability by species to stressor: ', s)

  if(!exists('am_spp_cells_fv')) {
    am_spp_cells_fv <- am_spp_cells %>%
      oharac::dt_join(am_vuln_fe %>% 
                        select(am_sid, fe_id) %>% distinct(), 
                      by = 'am_sid', type = 'inner') %>%
      group_by(loiczid, fe_id) %>%
      mutate(nspp_fe = n(), ### only one observation per am_sid per cell
             fv = 0.5^(nspp_fe - 1)) %>%
      ungroup()
  }

  am_vuln_str <- am_vuln_fe %>%
    filter(stressor == s) %>%
    select(-fe_id) %>%
    distinct()
  am_spp_vuln_cells <- am_spp_cells_fv %>%
    oharac::dt_join(am_vuln_str, by = c('am_sid'), type = 'inner')
  
  message('summarizing by FE in each cell...')
  result_df <- am_spp_vuln_cells %>%
    filter(!is.na(score)) %>%
    group_by(loiczid, fe_id, fv, nspp_fe) %>%
    ### first, summarize by FE per cell...
    summarize(score_mean1 = mean(score),
              # score_sd   = sd(score),
              .groups = 'drop')
  
  message('...then summarizing weighted mean across all FEs in each cell...')
  result_df <- result_df %>%
    group_by(loiczid) %>%
    ### ... then average across all FEs
    summarize(score_mean = Hmisc::wtd.mean(score_mean1, weights = fv),
              # score_sd   = sqrt(sum(score_sd^2 * fv, na.rm = TRUE) / sum(fv)),
              # score_sd   = sqrt(Hmisc::wtd.var(score_mean1, weights = fv)),
                ### weighted std dev among mean scores for each FE
              n_spp      = sum(nspp_fe),
              .groups = 'drop')
    
  rast_mean <- map_to_hcaf(result_df, which = 'score_mean')
  # rast_sd   <- map_to_hcaf(result_df, which = 'score_sd')

  writeRaster(rast_mean, sprintf(out_stem, s, 'mean'), overwrite = TRUE)
  # writeRaster(rast_sd,   sprintf(out_stem, s, 'sd'), overwrite = TRUE)
}
```

```{r plot weighted vuln by FE by stressor, fig.height = 4, fig.width = 10}
mean_fs <- list.files(here('_output/vuln_by_fe_weighted'), pattern = 'mean', full.names = TRUE)
# sd_fs   <- list.files(here('_output/vuln_wt_by_fe'), pattern = 'sd', full.names = TRUE)

mean_fs <- mean_fs[str_detect(basename(mean_fs), focal_strs)]

mean_stack <- raster::stack(mean_fs) %>%
  setNames(str_remove(names(.), 'vuln_wt_by_fe_'))
# sd_stack   <- raster::stack(sd_fs) %>%
#   setNames(str_remove(names(.), 'vuln_wt_by_fe_'))

plot(mean_stack, zlim = c(0, 1), col = map_cols,
     legend = FALSE, axes = FALSE)
# plot(sd_stack,   zlim = c(0, 1), legend = FALSE, axes = FALSE)
```