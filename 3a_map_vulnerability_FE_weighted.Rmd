---
title: "Map vulnerability - weighted by functional vulnerability"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/src/templates/ohara_hdr.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(raster)
library(oharac)
library(tidyverse)
library(here)
source(here('common_fxns.R'))

```

# Summary

Apply vulnerability scores to mapped species.  Map out vulnerability to each stressor, first unweighted by species (each spp counts same, see script 2), then weighted by functional vulnerability (FEs with higher FV are given greater weight, this script).

# Data

* AquaMaps and IUCN rangemaps
* Vulnerability Framework data for vulnerability scores
* FishBase/SeaLifeBase and vulnerability framework data for functional entity assignments

# Methods

## Functional vulnerability weighted

Read in AquaMaps and IUCN maps and vulnerability scores.  AquaMaps maps will exclude species with fewer than 10 occurrence cells, and will use a probability threshold of 0.5.  Here, we can include all species in the intersection of (mapped $\cap$ trait-based vulnerability) without worrying about functional entity membership.

To calculate functional vulnerability of species within a cell, we must know all species in that cell (and their FE membership).  But loading in all spp maps simultaneously will likely be too memory intensive.  Because of the number of cells and species, we will break the map into chunks of e.g., 100,000 cells at a time.  For each chunk, we will read in each species map, filtering to the chunk cells only to keep the memory needs down, bind the lookup of species-to-functional entity, calculate functional vulnerability for each FE for each cell.  Then, iterating over each stressor, for that chunk, calculate FV-weighted mean and sd vulnerability (as well as total FV weight value).  Save all chunk data as temp files, then combine per stressor.

```{r}
spp_am <- get_am_spp_info()  %>%
  filter(occur_cells >= 10) %>%
  select(species = sciname) %>%
  mutate(am_mapped = TRUE) %>%
  distinct()

spp_iucn <- read_csv(here('_data/iucn_spp/iucn_to_worms_match.csv'), show_col_types = FALSE) %>%
  rename(species = worms_name, iucn_mapped = mapped)

spp_vuln <- get_spp_vuln(gapfill = 'family') %>%
  select(species, stressor, taxon, score, sd_score)  %>%
  mutate(vuln = TRUE) %>%
  distinct()

spp_worms <- assemble_worms() %>%
  select(species) %>%
  mutate(worms = TRUE) %>%
  distinct()

spp_fe <- read_csv(here('_output/func_entities/fe_species.csv'), show_col_types = FALSE)

all_spp <- spp_worms %>%
  full_join(spp_vuln, by = 'species') %>%
  full_join(spp_am,   by = 'species') %>%
  full_join(spp_iucn, by = 'species') %>%
  full_join(spp_fe,   by = 'species')

spp_for_vuln_calc <- all_spp %>%
  ### names in WoRMS
  filter(worms) %>%
  ### only those spp in vulnerability project?
  filter(vuln) %>%
  ### mapped in AquaMaps and/or IUCN
  filter(am_mapped | iucn_mapped) %>%
  ### and with valid FE classification
  filter(!is.na(fe_id))

```

Because of need to overlap species with range maps, vulnerability scores, and functional entity membership, this analysis includes `r spp_for_vuln_calc$species %>% n_distinct()` species.

### Temporary cell cluster FE-weighted vulnerability maps

Functional vulnerability for a functional entity will be calculated based on the number of species $N_{spp}$ in the FE:

$$FV_{FE} = \frac{1}{2^{N_{spp}-1}}$$
The formulation by Sebastien Villeger calculates $FV$ as the proportion of FEs represented by only a single species.  This new formulation accounts for vulnerability of FEs with low membership, and quickly drops off as membership increases - e.g., an FE with two members is given FV of 0.5, while an FE with ten members is given FV of 0.002. 

Overall functional vulnerability of a cell will be the average of FV across all $N_{FE}$ FEs in the cell:
$$FV = \frac{\sum FV_{FE}}{N_{FE}}$$

Using the Villeger metric ($FV_i \in \{0, 1\}$) this simplifies to the proportion of FEs represented by a single species.

Then, the FV-weighted mean vulnerability $V_{FV}^{s,i}$ of a functional entity $i$ to a stressor $s$ is calculated as the average stressor vulnerability $v_s$ of all spp $j \in 1:N_{spp,i}$in that FE, times the functional vulnerability:
$$V_{FV}^{s,i} = FV_i \times \frac{1}{N_{spp,i}}\sum_{j=1}^{N_{spp,i}} v_{s,j} = FV_i \times \bar v_s$$
Using the Villeger metric ($FV_i \in \{0, 1\}$), $V_{FV}^{s,i}$ is zero for FEs with $N_{spp,i} > 1$ and equal to $v_{s,1}$ for FEs with $N_{spp,i} = 1$.

The cell overall FV-weighted mean vulnerability to stressor $s$ is:
$$V_{FV}^{s} = \frac{1}{\sum_{k=1}^{N_{FE}} FV_k} \sum_{i=1}^{N_{FE}} FV_i \times \bar v_s = \frac{1}{\sum_{k=1}^{N_{FE}} FV_k} \sum_{i=1}^{N_{FE}} V_{FV}^{s,i}$$

#### Note on mean and sd:

When working with unweighted vulnerabilities (with species counts) we could take a pooled variance approach to determining the standard deviation of vulnerability across all species present in a cell.  Here, the unit of analysis is a functional entity, and weighted not by the number of species in each FE but rather by the functional vulnerability of that FE.  A weighted pooled variance may be possible, but here we will simply report the FV-weighted mean across all FEs in the cell, and standard deviation of FV-weighted mean across all FEs.  This loses information on variance of vulnerability within each FE but that may not be that interesting or critical.

#### Tidy the loop

Because this is a complex process, let's tidy the big `for` loop by breaking out key code as functions.

* `read_truncated_rangemap`: read in all range maps, truncating each one to just those cells in the current chunk.
* `calc_fv`: Calculate the functional vulnerability for a given functional entity based on the number of spp present.
* `calc_spp_cell_fv`: For each cell, identify all FEs and calculate the FV of each.  Because grouping by large numbers of groups (e.g, 100000 cells and multiple FEs), for crash-avoidance, this is parallelized. 
* `bind_maps_list`: for a list of truncated species maps, clean out NULL results and bind rows, keeping cell ID and species name.
* `calc_chunk_str_sum`: for a dataframe of truncated species maps

```{r helper functions}
read_truncated_rangemap <- function(f, chunk_start, chunk_end) {
  ### Identify the source from filename (for filtering by presence or prob)
  src <- ifelse(str_detect(basename(f), 'iucn_spp_mol'), 'iucn', 'am')
  df <- data.table::fread(f) %>%
    filter(between(cell_id, chunk_start, chunk_end)) %>%
    mutate(map_f = f)
  if(src == 'iucn') {
    df <- df %>%
      filter(presence != 5) %>% 
      select(-presence)
  } else {
    df <- df %>%
      filter(prob >= .5) %>%
      select(-prob)
  }
  if(nrow(df) == 0) return(NULL) else return(df)
}

bind_maps_list <- function(chunk_maps_list, spp_map_fs) {
  ### NOTE: for some reason, the bind_rows() in here sometimes causes
  ### unrecoverable errors when knitting, but seems OK when running chunks
  ### individually... try subbing with data.table::rbindlist 
  chunk_maps_raw <- chunk_maps_list %>%
    ### drop NULL instances (no spp cells - helps keep things from crashing)
    purrr::compact() %>% 
    data.table::rbindlist() 
  
  if(nrow(chunk_maps_raw) > 0) {
    ### if no spp-cell data for this chunk, skip bind and return 0-length df
    chunk_maps_raw <- chunk_maps_raw %>%
      oharac::dt_join(spp_map_fs, by = 'map_f', type = 'left') %>%
      select(-map_f, -src) %>%
      distinct()
  }
  return(chunk_maps_raw)
}

calc_chunk_str_sum <- function(chunk_maps, spp_for_vuln_calc, str) {
  chunk_spp_for_vuln_calc <- spp_for_vuln_calc %>%
    filter(stressor == str) %>%
    filter(species %in% chunk_maps$species) %>%
    select(species, score, sd_score) %>%
    distinct()
  
  cell_id_df <- data.frame(cell_id = chunk_maps$cell_id %>% unique()) %>%
    mutate(cell_gp = rep(1:100, length.out = n()))
  cell_gps <- cell_id_df$cell_gp %>% unique()

  chunk_spp_str_vuln <- chunk_maps %>%
    oharac::dt_join(chunk_spp_for_vuln_calc, by = 'species', type = 'inner') 
  
  ### parallelize for speed! balance vectorization with parallel to reduce crashing...
  chunk_str_vuln_list <- parallel::mclapply(cell_gps, mc.cores = 30,
          FUN = function(gp) { ### gp <- 2
            cell_ids <- cell_id_df %>% 
              filter(cell_gp == gp) %>% 
              .$cell_id
            df <- chunk_spp_str_vuln %>%
              filter(cell_id %in% cell_ids) %>%
              group_by(cell_id, fe_id) %>%
              summarize(score_mean = mean(score), # %>% round(5),
                        score_sd   = sd(score), # %>% round(5),
                        n_spp      = n_distinct(species),
                        ### super-tiny fv (~ 1e-20) result in Inf var
                        fv = first(fv) %>% round(10),
                        .groups = 'drop') %>%
              group_by(cell_id) %>%
              summarize(n_spp = sum(n_spp),
                        fv_wt_mean_vuln = Hmisc::wtd.mean(score_mean, weights = fv),
                        fv_wt_sd_vuln   = sqrt(Hmisc::wtd.var(score_mean, weights = fv)))
          })
  chunk_str_sum_df <- data.table::rbindlist(chunk_str_vuln_list)
  return(chunk_str_sum_df)
}

calc_fv <- function(n_spp) {
  k <- n_spp - 1
  fv <- 0.5^k
} 

calc_spp_cell_fv <- function(chunk_maps_raw, spp_fe) {
  ### parallelize this mf to keep group_by from crashing everything - but not
  ### for every cell individually!  Set up 1000 different cell groups across 
  ### the 100k(ish) cells - divide work between dplyr and parallel...
  cell_id_df <- data.frame(cell_id = chunk_maps_raw$cell_id %>% unique()) %>%
    mutate(cell_gp = rep(1:100, length.out = n()))
  cell_gps <- cell_id_df$cell_gp %>% unique()
  
  fe_df <- chunk_maps_raw %>%
    left_join(spp_fe %>% select(species, fe_id), by = 'species')
  fv_list <- parallel::mclapply(cell_gps, mc.cores = 30,
                                FUN = function(gp) { 
                                  ### gp <- 52
                                  cell_ids <- cell_id_df %>% 
                                    filter(cell_gp == gp) %>% 
                                    .$cell_id
                                  x <- fe_df %>%
                                    filter(cell_id %in% cell_ids) %>%
                                    group_by(cell_id) %>%
                                    mutate(n_spp = n_distinct(species),
                                           n_fes = n_distinct(fe_id)) %>%
                                    group_by(cell_id, fe_id) %>%
                                    mutate(n_spp_fe = n_distinct(species),
                                           fv = calc_fv(n_distinct(species))) %>%
                                    ungroup()
                                  return(x)
                                })
  fv_df <- data.table::rbindlist(fv_list)
  return(fv_df)
}
```

```{r vuln by species iterating over stressors and chunks of cells}

spp_map_fstem <- here_anx('spp_maps_mol', '%s_spp_mol_%s.csv')
spp_map_fs <- spp_for_vuln_calc %>%
  select(species, am_mapped, iucn_mapped, iucn_sid) %>%
  distinct() %>%
  mutate(src = ifelse(iucn_mapped & !is.na(iucn_mapped), 'iucn', 'am'),
         id  = ifelse(src == 'iucn', iucn_sid, str_replace_all(species, ' ', '_')),
         map_f = sprintf(spp_map_fstem, src, id)) %>%
  select(species, src, map_f) %>%
  ### two duped map files for a couple of coral spp: just keep one!
  group_by(map_f) %>%
  filter(species == first(species)) %>%
  distinct()
  
n_cells <- ncell(raster(here('_spatial/ocean_area_mol.tif')))
chunk_size <- 100000
n_chunks <- ceiling(n_cells / chunk_size)

strs <- spp_for_vuln_calc$stressor %>% unique() %>% sort()

out_stem <- here('tmp/vuln_fe_wt_chunks/vuln_summary_chunk_%s_to_%s_%s.csv')
  ### format will be: chunk start, chunk end, stressor

for(chunk_i in 1:n_chunks) { ### chunk_i <- 65
  
  ### Set up chunk start and end and filenames; check whether maps 
  ### all stressors for this chunk...
  chunk_start <- (chunk_i - 1) * chunk_size + 1
  chunk_end   <- as.integer(chunk_i * chunk_size)
  chunk_text <- sprintf('chunk %s of %s (cells %s to %s)', chunk_i, n_chunks, chunk_start, chunk_end)

  ### check if all chunk-stressor maps are complete
  outf_all_strs <- sprintf(out_stem, chunk_start, chunk_end, strs)
  if(all(file.exists(outf_all_strs))) {
    message('All stressor summaries exist for ', chunk_text, '... skipping!')
    next()
  }
  
  ### Some chunk maps remain, so continue:
  ### Load species rangemaps for this chunk, then clean and bind:
  message('Loading ', nrow(spp_map_fs), ' rangemaps cropped for ', chunk_text,  '...')
  
  chunk_maps_list <- parallel::mclapply(spp_map_fs$map_f, mc.cores = 30, 
                                        ### f <- spp_map_fs$map_f[1]
                                        FUN = read_truncated_rangemap, 
                                        chunk_start = chunk_start, chunk_end = chunk_end) 
  
  chunk_maps_raw <- bind_maps_list(chunk_maps_list, spp_map_fs)
  
  ### if result includes no cells, write out empty chunk files
  if(nrow(chunk_maps_raw) == 0) {
    message('No species X cells found for ', chunk_text, '... skipping to next chunk!')
    lapply(outf_all_strs, FUN = function(x) write_csv(data.frame(cell_id = -1), x))
    next()
  }

  ### OK, now we have species and cells for this chunk.  Calculate functional vulnerability!
  message('Calculating functional vulnerability metrics for ', chunk_text, '...')
  chunk_maps <- chunk_maps_raw %>%
    calc_spp_cell_fv(spp_fe)
  
  message('In ', chunk_text,  ' rangemap dataframe: \n    ', nrow(chunk_maps), 
          ' cell observations for ', n_distinct(chunk_maps$species), ' species across ',
          n_distinct(chunk_maps$fe_id), ' functional entities...')
  
  ### For this chunk, loop over all stressors, summarize FV-weighted mean and sd
  for(s in strs) {
    ### s <- strs[2]
    outf_this_str <- sprintf(out_stem, chunk_start, chunk_end, s)
    if(file.exists(outf_this_str)) {
      message('Temp csv exists for ', chunk_text, ' for stressor ', s, '... skipping!')
      next()
    }

    message('Processing mean/sd vuln in ', chunk_text, ' to stressor: ', s)
    chunk_str_sum <- calc_chunk_str_sum(chunk_maps, spp_for_vuln_calc, str = s)
    
    write_csv(chunk_str_sum, outf_this_str)
  }
}

```

### Aggregate chunk vulnerability maps to global map

For each stressor, pull in all chunk dataframes, assemble into dataframe, and save out as rasters.

```{r assemble chunk vuln maps to total maps}

chunk_files <- list.files(dirname(out_stem), pattern = 'vuln_summary_chunk', full.names = TRUE)

chunk_file_df <- data.frame(f = chunk_files) %>%
  mutate(stressor = str_remove_all(basename(f), '.+[0-9]+_|.csv'))

rast_out_stem <- here('_output/vuln_maps_fv_weighted/vuln_fv_wt_%s_%s.tif')
for(str in strs) { ### str <- strs[2]
  rast_mean_vuln_f <- sprintf(rast_out_stem, str, 'mean')
  rast_sdev_vuln_f <- sprintf(rast_out_stem, str, 'sdev')
  
  if(all(file.exists(rast_mean_vuln_f, rast_sdev_vuln_f))) next()
  
  message('Gathering vulnerability chunk maps for ', str, '...')
  str_chunk_fs <- chunk_file_df %>%
    filter(stressor == str) %>%
    .$f
  vuln_map_df <- parallel::mclapply(str_chunk_fs, mc.cores = 33, FUN = data.table::fread) %>%
    bind_rows() %>%
    mutate(fv_wt_mean_vuln = round(fv_wt_mean_vuln, 5),
           fv_wt_sd_vuln   = round(fv_wt_sd_vuln,   5))
  
  message('Converting vulnerability maps to rasters for ', str, '...')
  rast_mean_vuln <- map_to_mol(vuln_map_df, by = 'cell_id', which = 'fv_wt_mean_vuln')
  rast_sdev_vuln <- map_to_mol(vuln_map_df, by = 'cell_id', which = 'fv_wt_sd_vuln')
  
  message('Writing vulnerability rasters for ', str, '...')
  writeRaster(rast_mean_vuln, rast_mean_vuln_f, overwrite = TRUE)
  writeRaster(rast_sdev_vuln, rast_sdev_vuln_f, overwrite = TRUE)
  
  fv_vuln_nspp_rast_f <- here('_output/nspp_maps/nspp_in_fv_weighted_vuln_maps.tif')
  if(!file.exists(fv_vuln_nspp_rast_f)) {
    message('Creating species richness raster for functional vulnerability maps...')
    rast_nspp_vuln <- map_to_mol(vuln_map_df, by = 'cell_id', which = 'n_spp')
    writeRaster(rast_nspp_vuln, fv_vuln_nspp_rast_f, overwrite = TRUE)
  }
}

```



## Plot example maps

```{r plot vuln by stressor, fig.height = 4, fig.width = 7}

vuln_all_spp_dir <- here('_output/vuln_maps_fv_weighted')
mean_fs <- list.files(vuln_all_spp_dir, pattern = '_mean.tif', full.names = TRUE)
sdev_fs <- list.files(vuln_all_spp_dir, pattern = '_sdev.tif', full.names = TRUE)

focal_strs <- c('biomass_removal', 'bycatch', 
                'microplastic', 'wildlife_strike',
                'nutrient_pollution', '_oa_', 
                'sst_rise', 'marine_heat_wave',
                'light_pollution')

for(f in focal_strs) { ### f <- focal_strs[1]
  mean_f <- mean_fs[str_detect(basename(mean_fs), f)]
  sdev_f <- sdev_fs[str_detect(basename(sdev_fs), f)]
  mean_rast <- raster::raster(mean_f)
  sdev_rast <- raster::raster(sdev_f)
  # sd_stack   <- raster::stack(sd_fs) %>%
  #   setNames(str_remove(names(.), 'vuln_by_spp_'))
  
  map_cols <- hcl.colors(n = 50)
  
  plot(mean_rast, zlim = c(0, 1), col = map_cols, main = paste0('Mean FV-weighted vuln: ', f),
       legend = FALSE, axes = FALSE)  
  # plot(sdev_rast, zlim = c(0, 1), col = map_cols, main = paste0('SD FV-weighted vuln: ', f),
  #      legend = FALSE, axes = FALSE)
}
```
