---
title: "Stressors: targeted fishing by species and cell - rescale stressor"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_depth: 1
    toc_float: yes
    number_sections: false
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/src/templates/ohara_hdr.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(raster)
library(oharac) ### remotes::install_github('oharac/oharac')
  ### includes some helper functions, e.g., dt_join
library(tidyverse)
library(here)

source(here('common_fxns.R'))
source('stressor_fxns.R') ### in same dir as this Rmd
```

# Summary

Read in rasters (as csvs) of NPP-adjusted fisheries catch per species per cell.  Identify a reference point and rescale stressor layers from 0-1 for each species.

# Data

Data from

* Watson, R.A. and Tidd, A.N. (2018) Mapping nearly a century and a half of global marine fishing: 1869 to 2015. Marine Policy 93, 171-177
* Watson, R. (2017) A database of global marine commercial, small-scale, illegal and unreported fisheries catch 1950-2014. Nature Scientific Data 4 (170039).

# Methods

* For each species, considering its entire range, identify the various percentiles of NPP-adjusted total catch. 
* Examine different threshold options to see what makes most sense as a threshold for rescaling.  Here we have chosen the highest value for 90th percentile across all species as a cutoff for overfishing, based on ability to distinguish overfishing on RAM stocks.
* For targeted species whose highest catch value falls below that threshold, normalize to their own 99th percentile.
* Normalize all species fishing stressor maps using that reference system and save out.

## Identify reference point

Take each species fishing map, expand out to include unfished cells in the species' range, and then determine the various quantiles of catch for each species, to explore potential cutoffs.

```{r set up vars}
watson_maps_lookup <- read_csv(here('1_setup/stressors/int/watson_maps_lookup.csv'))

spp_vec <- watson_maps_lookup$spp %>% unique() %>% sort()

npp_catch_dir <- here_anx('stressors/fishing/3_npp_norm_catch_by_spp_moll')

npp_catch_fs <- list.files(npp_catch_dir, full.names = TRUE)

```

``` {r calc ref point by range}
calc_quantiles_range <- function(f, fstem) {
  # f <- npp_catch_fs[1]
  i <- which(f == npp_catch_fs)
  
  s_snake <- basename(f) %>% 
    str_remove_all('.+spp_npp_catch_|_mol.csv')
  s <- s_snake %>% str_replace_all('_', ' ')
  src <- basename(f) %>% str_remove_all('_spp_npp_catch.+')

  out_f <- sprintf(fstem, s_snake, src)

  if(!file.exists(out_f)) {
    message('Processing ', s, ' (', i, ' of ', length(npp_catch_fs), ') based on ', toupper(src), ' rangemaps...')
    catch_df <- data.table::fread(f)
    
    if(src == 'am') {
      range_df <- data.table::fread(sprintf(here_anx('spp_maps_mol', '%s_spp_mol_%s.csv'), src, s_snake))
    } else {
      ### src is IUCN, and file(s) by ID - perhaps multiple IDs for a given spp?
      iucn_ids <- watson_maps_lookup %>%
        filter(spp == s) %>%
        .$iucn_sid %>% unique()
      range_fs <- sprintf(here_anx('spp_maps_mol', '%s_spp_mol_%s.csv'), src, iucn_ids)
      range_df <- lapply(range_fs, read_csv, show_col_types = FALSE) %>%
        bind_rows() %>%
        distinct()
    }
    
    ### blank vector of spp range (begin with catch = 0)
    v <- rep(0, times = n_distinct(range_df$cell_id))
    if(nrow(catch_df) > 0) {
      ### create vector of total normalized catch
      npp_catch_sum <- catch_df %>%
        mutate(tot_norm_catch = ben_norm_catch + pel_norm_catch) %>%
        .$tot_norm_catch
      tot_npp_catch <- sum(npp_catch_sum)
      tot_catch <- sum(catch_df$ben_tot_catch + catch_df$pel_tot_catch)
      
      ### overwrite catch values onto catch-relevant spp range
      v[1:length(npp_catch_sum)] <- npp_catch_sum
    } else {
      # v is unchanged, all zeros
      tot_catch <- 0
      tot_npp_catch <- 0
    }
    z <- quantile(v, c(.50, .9, .95, .99, .999, 1.0))
    df <- as.matrix(z) %>% t() %>%
      as.data.frame() %>%
      mutate(spp = s,
             source = src,
             tot_catch = tot_catch,
             tot_npp_catch = tot_npp_catch)
    write_csv(df, out_f)
  }
}
```

``` {r}

fishing_ref_f <- here('1_setup/stressors/int/fish_npp_catch_ref_point.csv')
# unlink(fishing_ref_f)
if(!file.exists(fishing_ref_f)) {
  
  ref_tmp_fstem <- here('tmp', 'fishing_str_ref_pts', 'fishing_str_ref_%s_%s.csv')
  ### zxcv <- list.files(dirname(ref_tmp_fstem), full.names = TRUE)
  ### unlink(zxcv)
  
  tmp <- parallel::mclapply(npp_catch_fs, mc.cores = 16,
                            FUN = calc_quantiles_range,
                            fstem = ref_tmp_fstem)

  tmp_fs <- list.files(here('tmp', 'fishing_str_ref_pts'),
                       pattern = 'fishing_str_ref', full.names = TRUE)
  # unlink(tmp_fs)
  fish_qtile_range_df <- parallel::mclapply(tmp_fs, 
                                            FUN = data.table::fread, 
                                            mc.cores = 24) %>%
    data.table::rbindlist() %>%
    janitor::clean_names() %>%
    arrange(desc(x99_percent))

  write_csv(fish_qtile_range_df, fishing_ref_f)
}

qtile_results <- read_csv(fishing_ref_f) %>%
  group_by(spp) %>%
  filter(n() == 1 | source == 'iucn') %>%
    ### pref IUCN for spp with both sources
  ungroup() %>%
  arrange(desc(x90_percent))
knitr::kable(head(qtile_results, 20), digits = 1)

```


### Check thresholds vs RAM

```{r}
ram_assess_f <- here('1_setup/stressors/int', 'ram_assess.csv')

if(!file.exists(ram_assess_f)) {
  ram_mazu <- '/home/shares/ohi/git-annex/globalprep/_raw_data/RAM/d2021/RAMLDB v4.495/R Data'
  load(file.path(ram_mazu, 'DBdata[asmt][v4.495].RData'))
  ram_spp <- stock %>%
    filter(state != 'Deprecated') %>%
    mutate(across(where(is.character), tolower)) %>%
    ### 1264 of 1372 spp in both datasets
    filter(scientificname %in% qtile_results$spp) %>%
    select(stockid, tsn, spp = scientificname) %>%
    distinct()
  
  ram_ts <- timeseries %>%
    filter(between(tsyear, 2015, 2017)) %>%
    mutate(across(where(is.character), tolower)) %>%
    filter(stockid %in% ram_spp$stockid) %>%
    filter(!is.na(tsvalue)) %>%
    left_join(ram_spp, by = 'stockid')
  
  bmsy_levels <- c("tbdivtbmgt-calc-dimensionless",
                   "tbdivtbmgt-dimensionless",
                   "tbdivtbmsy-calc-dimensionless",
                   "tbdivtbmsy-dimensionless",
                   "ssbdivssbmgt-calc-dimensionless",
                   "ssbdivssbmsy-calc-dimensionless",
                   "ssbdivssbmsy-dimensionless",
                   "bdivbmgtpref-dimensionless",
                   "bdivbmsypref-dimensionless",
                   "bdivbmgttouse-dimensionless",    
                   "bdivbmsytouse-dimensionless")
  ram_ts_bdivbmsy <- ram_ts %>%
    filter(tsid %in% bmsy_levels) %>%
    mutate(tsid = factor(tsid, levels = bmsy_levels)) %>%
    group_by(spp, stockid, tsyear) %>%
    filter(as.integer(tsid) == max(as.integer(tsid))) %>%
    summarize(tsvalue = mean(tsvalue),
              overfished = tsvalue < 1) %>%
    select(spp, stockid, year = tsyear, overfished) %>%
    distinct()
  
  fmsy_levels <- c("cdivmsy-ratio",
                   "fdivfmgt-calc-dimensionless",
                   "fdivfmsy-calc-dimensionless",
                   "fdivfmsy-dimensionless",
                   "udivumgtpref-dimensionless",
                   "udivumsypref-dimensionless",
                   "udivumgttouse-dimensionless",
                   "udivumsytouse-dimensionless")
  ram_ts_fdivfmsy <- ram_ts %>%
    filter(tsid %in% fmsy_levels) %>%
    mutate(tsid = factor(tsid, levels = fmsy_levels)) %>%
    group_by(spp, stockid, tsyear) %>%
    filter(as.integer(tsid) == max(as.integer(tsid))) %>%
    summarize(tsvalue = mean(tsvalue),
              overfishing = tsvalue > 1) %>%
    select(spp, stockid, year = tsyear, overfishing) %>%
    distinct()

  ram_assess <- ram_ts_bdivbmsy %>%
    full_join(ram_ts_fdivfmsy, by = c('spp', 'stockid', 'year'))
  
  write_csv(ram_assess, ram_assess_f)
}
```

``` {r}
ram_assess <- read_csv(ram_assess_f)

prop_overfished <- ram_assess %>%
  group_by(year) %>%
  summarize(pct_overfished  = sum(overfished,  na.rm = TRUE) / sum(!is.na(overfished)),
            pct_overfishing = sum(overfishing, na.rm = TRUE) / sum(!is.na(overfishing)))

ref_pt <- max(qtile_results$x90_percent, na.rm = TRUE)
ref_spp <- qtile_results$spp[which(qtile_results$x90_percent == ref_pt)] %>%
  str_to_sentence()

ram_assess_over <- ram_assess %>%
  group_by(spp) %>%
  summarize(overfished  = ifelse(any(!is.na(overfished)), sum(overfished, na.rm = TRUE) > 0, NA),
            overfishing = ifelse(any(!is.na(overfishing)), sum(overfishing, na.rm = TRUE) > 0, NA))
ram_check <- qtile_results %>%
  inner_join(ram_assess_over, by = 'spp') %>%
  mutate(over_thresh = x100_percent >= ref_pt)

overfished <- table(ram_check %>% select(overfished, over_thresh))
overfishing <- table(ram_check %>% select(overfishing, over_thresh))
# chisq.test(overfished)
# chisq.test(overfishing)
```

According to RAM Legacy database, proportion of stocks overfished ($B/B_{msy}$ or similar) and overfishing/overexploited ($F/F_{msy}$ or similar) across 2015-2017 (same years as Watson data):

```{r}
knitr::kable(prop_overfished, digits = 3)
```

Overfishing (fishing mortality) seems like the relevant comparison to fishing pressure, rather than overfished (stock status).  Comparing species whose max catch value in a cell exceeds the highest 90%ile reference point (columns) to those species with at least one year/stock combo considered overexploited (rows):

```{r}
knitr::kable(overfishing)
```

This threshold seems to avoid calling reasonably exploited stocks overexploited, though it is 50/50 at identifying overexploited stocks.  Performing a $\Chi^2$ test:

```{r}
chisq.test(overfishing)
```

Based on this method, the max cutoff reference point for NPP-adjusted targeted catch is $C_{ref} = $`r round(ref_pt)` tonnes/log(NPP), for species <i>`r ref_spp`</i>.  However, for species whose 99.9th percentile catch falls below this reference point, we will use the 99.9th percentile of that species' catch as its own reference point.  For catch $C$ for species $i$:

$$C_{ref}^i = \min (C_{ref}, C_{99.9\%}^i)$$
 
By this method, 82 of the highest-fished spp will be subject to the reference cap of $C_{ref} = $`r round(ref_pt)` tonnes/log(NPP).

## Rescale NPP-adjusted targeted catch layers

Using this reference system, rescale NPP-adjusted catch layers for each species, and save out the finalized stressor file for each.

```{r rescale catch}
rescale_catch <- function(df) {
  # df <- rescale_todo_df %>% slice(10)
  out_f <- df$rescaled_f
  
  if(!file.exists(out_f)) {
    in_f <- df$npp_f
    ref_pt <- df$spp_ref_pt

    message('Rescaling catch based on ', basename(in_f), 
            ', \n    ref pt = ', round(ref_pt, 2), ' t/log(NPP)... (', df$i, 
            ' of ', nrow(rescale_todo_df), ')')
    
    catch_df <- read_csv(in_f, show_col_types = FALSE)
    if(nrow(catch_df) == 0) {
      rescaled_df <- data.frame(cell_id = -1, rescaled_catch = 0)
    } else {
      rescaled_df <- catch_df %>%
        mutate(tot_c = pel_norm_catch + ben_norm_catch,
               rescaled_catch = case_when(ref_pt == 0 ~ 0,
                                          tot_c < ref_pt ~ tot_c / ref_pt, 
                                          TRUE ~ 1)) %>%
        select(cell_id, rescaled_catch)
    }
    write_csv(rescaled_df, out_f)
    
  } else {
    # message('... File exists: ', basename(out_f), '... skipping!')
  }
}
```

``` {r}
rescaled_fstem <- here_anx('stressors/fishing/4_rescaled_catch_by_spp_cell',
                           '%s_spp_rescaled_catch_%s.csv')

reference_df <- data.frame(npp_f = npp_catch_fs) %>%
  mutate(source = str_remove(basename(npp_f), '_spp_npp_catch.+'),
         spp = str_remove_all(basename(npp_f), '.+_spp_npp_catch_|_mol.csv'),
         rescaled_f = sprintf(rescaled_fstem, source, spp),
         spp_clean = str_replace_all(spp, '_', ' ')) %>%
  left_join(qtile_results, by = c('spp_clean' = 'spp')) %>%
  mutate(spp_ref_pt = ifelse(x99_9_percent > ref_pt, ref_pt, x99_9_percent),
         ### some spp with no 99.9%ile catch - just use max as ref
         spp_ref_pt = ifelse(spp_ref_pt < 1e-6, x100_percent, spp_ref_pt)) %>%
  select(spp, npp_f, rescaled_f, spp_ref_pt)

rescale_todo_df <- reference_df %>%
  filter(!file.exists(rescaled_f))

### y <- list.files(dirname(rescaled_fstem), full.names = TRUE)
### unlink(y)

tmp <- parallel::mclapply(1:nrow(rescale_todo_df), mc.cores = 32,
                          FUN = function(i) { ### i <- 1017
                            rescale_catch(df = rescale_todo_df %>% slice(i) %>% mutate(i))
                          })

# df <- data.frame(s = spp_vec, f = sprintf(rescaled_fstem, spp_vec)) %>%
#   mutate(f = str_replace_all(f, ' ', '_'))
# fs <- list.files(dirname(rescaled_fstem), full.names = TRUE)
# missing_spp <- df %>%
#   filter(!f %in% fs) %>%
#   .$s
# 
# tmp <- parallel::mclapply(missing_spp, mc.cores = 24, 
#                           FUN = rescale_catch, ref_pt = ref_pt)

```

```{r check files}
fs <- list.files(dirname(rescaled_fstem), full.names = TRUE)
df <- data.frame(f = basename(fs), fsize = file.size(fs)) %>%
  arrange(desc(fsize))

knitr::kable(head(df, 10))
```


