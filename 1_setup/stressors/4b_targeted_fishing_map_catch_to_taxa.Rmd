---
title: "Stressors: targeted fishing by species and cell - calculate total fishing catch"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_depth: 1
    toc_float: yes
    number_sections: false
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/src/templates/ohara_hdr.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(oharac) ### remotes::install_github('oharac/oharac')
  ### includes some helper functions, e.g., dt_join
library(tidyverse)
library(here)

source(here('common_fxns.R'))
source('stressor_fxns.R') ### in same dir as this Rmd
```

# Summary

Read in data from Watson (2018) and collapse down to targeted catch by taxon and cell, across benthic gear types and pelagic gear types separately.  Save out as rasters (or csvs) per species.

# Data

Data from

* Watson, R.A. and Tidd, A.N. (2018) Mapping nearly a century and a half of global marine fishing: 1869 to 2015. Marine Policy 93, 171-177
* Watson, R. (2017) A database of global marine commercial, small-scale, illegal and unreported fisheries catch 1950-2014. Nature Scientific Data 4 (170039).

Included in data:

* Industrial Catch (1950 - 2017) - reported, iuu, and discard catch data for each cell location and unique identifier
* Non-Industrial Catch (1950 - 2017) - reported, iuu, and discard catch data for each cell location and unique identifier
* DATA CODE DEFINITIONS (gear/taxa/country codes and cell lat/lon references)

# Methods

## Read in Watson/WoRMS lookup and generate master list of taxa

The Watson/WoRMS lookup contains many species, but also higher-order taxa. Expand out to the species level.

```{r read in watson and aquamaps taxa data}
am_spp_ids <- get_am_spp_info() %>%
  filter(occur_cells >= 10) %>%
  select(am_sid, sciname) %>%
  distinct()

iucn_spp_ids <- read_csv(here('_data/iucn_spp/iucn_to_worms_match.csv')) %>%
  filter(mapped) %>%
  select(iucn_sid, worms_name) %>%
  distinct()

worms_long <- assemble_worms(aspect = 'long')

### Watson taxa recoded to match with WoRMS
watson_worms_tx_df <- read_csv(here('_raw/worms_to_watson_lookup.csv')) 

### Watson taxa, expanded to species, joined to AM and IUCN maps
watson_worms_spp_df <- watson_worms_tx_df %>%
  left_join(worms_long, by = c('worms_name' = 'name')) %>%
  left_join(am_spp_ids, by = c('spp' = 'sciname')) %>%
  left_join(iucn_spp_ids, by = c('spp' = 'worms_name'))

### Keep just the ones with maps:
watson_maps_spp_df <- watson_worms_spp_df %>%
  filter(!is.na(am_sid) | !is.na(iucn_sid)) %>%
  mutate(source = ifelse(!is.na(am_sid), 'aquamaps', 'iucn'))

# watson_worms_spp_df$spp %>% n_distinct() 
    # 96053 total species
# watson_maps_spp_df %>% filter(!is.na(am_sid)) %>% .$am_sid %>% n_distinct() 
    # 18368 spp ids in AquaMaps (25099 if no occurcells cut)
# watson_maps_spp_df %>% filter(!is.na(iucn_sid)) %>% .$iucn_sid %>% n_distinct() 
    # 5079 spp ids in IUCN
# watson_maps_spp_df$spp %>% n_distinct() 
    # 20326 distinct species across AquaMaps and IUCN (26169 if no occur_cells cut)
### how many spp from each source, prioritizing AquaMaps?
# table(watson_maps_spp_df %>% select(iucn_sid, am_sid, source) %>% distinct() %>% .$source)
    # aquamaps     iucn 
    #    18393     2179
```

## Higher-order taxonomic catch data

For higher-order taxonomic fishing data (i.e., not at species level):

* Identify all spp in that taxon with species distributions in AquaMaps and IUCN.
    * Prioritize AquaMaps range maps with occurcells >= 10, then IUCN.
* Generate a map of spp richness for the taxon (unique spp in each cell).
    * For AquaMaps maps, use probability threshold of 50%.
* Map out total catch across pelagic and benthic gear types for this taxon.
* Save out as a dataframe of cell ID, total catch, number of species.  Alternately: raster of catch, raster of species.  Use Watson `taxonkey` in filename.
    * It is quite convenient that Watson's cell ID is identical to LOICZID.
    * should it be an `inner_join` to reduce resulting files and duplicated info? the taxon-level map is unimportant beyond this step (for now) so yes.
    * Number of species can be used to portion out catch uniformly among members of the taxon present in the cell.

Note that there are many duplicates at higher orders - e.g., there are three separate `taxonkey` values for general marine fishes (Actinopterygii).  But since catch values are assigned to each of these, it is possible that in a single cell, some catch is associated with each of the taxon keys... so the catch is additive across all.

```{r read in watson catch data}
w_dir <- here_anx('../../git-annex/globalprep/_raw_data', 
                  'IMAS_GlobalFisheriesLandings/d2020')

w_codes_xlsx <- file.path(w_dir, 'Codes_raw.xlsx')
# codes_sheets <- readxl::excel_sheets(codes_xlsx)
w_cell_df <- readxl::read_excel(w_codes_xlsx, sheet = 'Cell') %>%
  janitor::clean_names() %>%
  select(-c(x5:x7))

w_gear_df <- readxl::read_excel(w_codes_xlsx, sheet = 'Gear') %>%
  janitor::clean_names() %>%
  select(-x9, -x10)
### Benthic gears: trap (f_gear_code = 4), dredge (5), trawl (6)

w_taxa_raw_df <- readxl::read_excel(w_codes_xlsx, sheet = 'Taxa') %>% 
  janitor::clean_names() %>%
  select(-c(x8:taxonkey_11), taxonkey = taxonkey_1)

w_catch_df <- readRDS(file.path(w_dir, 'Catch2015_2019.rds')) %>%
  janitor::clean_names() %>%
  mutate(benthic = f_gear_code %in% 4:6)

tons_by_pel_benth <- w_catch_df %>%
  filter(i_year == 2016) %>%
  group_by(benthic) %>%
  summarize(tot_tonnes = sum(reported_ind + reported_nind + iuuind + iuunind))

```

### Check catch levels across various taxonomic levels

Check 2016 catch to get an idea of how much catch is aggregated into higher-order taxa.

```{r summarize catch data across taxa for inspection}
summary_catch_by_tx <- w_catch_df %>%
  filter(i_year == 2016) %>%
  group_by(taxonkey) %>%
  summarize(tot_ind = sum(reported_ind + iuuind),
            tot_nind = sum(reported_nind + iuunind),
            tot_catch = tot_ind + tot_nind) %>%
  mutate(level = floor(taxonkey / 1e5))

tx_missing <- w_taxa_raw_df %>%
  filter(!taxonkey %in% summary_catch_by_tx$taxonkey)

ggplot(summary_catch_by_tx, aes(x = level, y = tot_catch)) +
  geom_jitter(width = .2, height = 0)

```

The large outlier is taxon 100039 (Marine fishes not identified, demersal <30 cm, Misc Finfishes) 

``` {r}
misc_finfish <- w_catch_df %>%
  filter(taxonkey == 100039) %>%
  filter(i_year == 2016) %>%
  summarize(tot_ind_catch = sum(reported_ind + iuuind),
            tot_nind_catch = sum(reported_nind + iuunind),
            tot_catch = tot_ind_catch + tot_nind_catch)
tot_2016 <- w_catch_df %>%
  filter(i_year == 2016) %>%
  summarize(tot_ind_catch = sum(reported_ind + iuuind),
            tot_nind_catch = sum(reported_nind + iuunind),
            tot_catch = tot_ind_catch + tot_nind_catch)

```

__NOTE:__  taxon 100039 (Marine fishes not identified, demersal <30 cm, Misc Finfishes) is a huge catch, nearly 1/10th total catch (reported and iuu).  Most is industrial.  This could skew results when assigning aggregated higher-level catch to species, unless we filter out the big fish (> 30 cm).  We can get length estimates from our functional entities post-imputation dataset.  Assume non-listed species are smaller than 30 cm; large spp are easier to identify.  

Apply the same size-sorting method to other higher-level taxa to the family level (4XXXXX and below), using descriptors of species as small (≤ 30 cm), large (≥ 90 cm), or in between (< 90 cm)

```{r clean taxa by filtering based on size}
spp_traits <- read_csv(here('_data/grouping_traits_post_imputation.csv')) %>%
  mutate(len = exp(log_l))

big_spp <- spp_traits %>%
  filter(len > 30) %>%
  .$species
huge_spp <- spp_traits %>%
  filter(len >= 90) %>%
  .$species

### less than 30 cm:
small_taxa <- w_taxa_raw_df %>%
  filter(taxonkey < 500000) %>%
  filter(str_detect(descript, '<30 cm')) %>% 
  .$taxonkey
### less than 90 cm:
mid_taxa   <- w_taxa_raw_df %>%
  filter(taxonkey < 500000) %>%
  filter(str_detect(descript, '<90 cm')) %>% 
  .$taxonkey
### larger than 90 cm:
large_taxa <- w_taxa_raw_df %>%
  filter(taxonkey < 500000) %>%
  filter(str_detect(descript, '>=90 cm')) %>% 
  .$taxonkey

watson_maps_cleaned_df <- watson_maps_spp_df %>%
  ### for small taxa, drop big_spp:
  filter(!(taxonkey %in% small_taxa & spp %in% big_spp)) %>%
  ### for medium taxa, drop huge_spp:
  filter(!(taxonkey %in% mid_taxa & spp %in% huge_spp)) %>%
  ### for large taxa, include only huge_spp:
  filter(!(taxonkey %in% large_taxa & !spp %in% huge_spp))
  
### write out lookup table for Watson taxonkey to AquaMaps/IUCN species and id
watson_maps_lookup <- watson_maps_cleaned_df %>%
  select(taxonkey, am_sid, iucn_sid, spp, source) %>%
  distinct()
write_csv(watson_maps_lookup, here('_setup/stressors/int/watson_maps_lookup.csv'))

```


### Process catch totals for higher level taxa

Functions to map the taxon species richness and total catch per cell for the taxon:

* `map_tx_spp_richness(spp_in_taxon, am_spp_cells, iucn_spp_cells)`
* `map_tx_catch(tx_id, catch_df)`

```{r helper functions}

map_tx_spp_rich <- function(spp_in_taxon, am_spp_cells, iucn_spp_cells) {
  
  am_sids <- spp_in_taxon %>%
    filter(source == 'aquamaps') %>%
    .$am_sid
  iucn_sids <- spp_in_taxon %>%
    filter(source == 'iucn') %>%
    .$iucn_sid
  
  ### find cells for all AquaMaps spp in this taxon
  am_tx_cells <- am_spp_cells %>%
    filter(am_sid %in% am_sids) %>%
    rename(id = am_sid)
  ### find cells for all IUCN spp in this taxon
  iucn_tx_cells <- iucn_spp_cells %>%
    filter(iucn_sid %in% iucn_sids) %>%
    mutate(id = as.character(iucn_sid)) ### to join with character am_sid

  
  tx_cell_sum <- am_tx_cells %>%
    bind_rows(iucn_tx_cells) %>%
    group_by(loiczid) %>%
    summarize(n_spp = n_distinct(id))
  
  if(nrow(tx_cell_sum) == 0) {
    message('  ... no species range found for ', paste(am_sids, iucn_sids, sep = ';', collapse = ';'), '!')
  }
  
  return(tx_cell_sum)
}

map_tx_catch <- function(tx_id, catch_df) {
  tx_catch_sum <- catch_df %>%
    filter(taxonkey %in% tx_id) %>%
    mutate(pel_ind_catch  = (reported_ind  + iuuind) * (!benthic),
           pel_nind_catch = (reported_nind + iuunind) * (!benthic),
           ben_ind_catch  = (reported_ind  + iuuind) * (benthic),
           ben_nind_catch = (reported_nind + iuunind) * (benthic)) %>%
    group_by(cell) %>%
    summarize(pel_ind_catch  = sum(pel_ind_catch),
              pel_nind_catch = sum(pel_nind_catch),
              ben_ind_catch  = sum(ben_ind_catch),
              ben_nind_catch = sum(ben_nind_catch),
              pel_tot_catch  = pel_ind_catch + pel_nind_catch,
              ben_tot_catch  = ben_ind_catch + ben_nind_catch)
  
  ### at this point, not using industrial vs non-industrial, so drop distinction.
  ### If it is needed, add to select() here:
  tx_catch_sum <- tx_catch_sum %>%
    select(cell, pel_tot_catch, ben_tot_catch)
  
  if(nrow(tx_catch_sum) == 0) {
    message('  ... no observed catch for taxon ', tx_id, '!')
  }
  return(tx_catch_sum)
}
```

Loop over higher-order taxa and generate taxon catch summary files.  For 100039, filter out big species specifically for a more accurate species richness value.  Write out to `stressors/fishing/1_total_catch_by_tx_cell` in the Mazu annex directory.

```{r Read in species maps}
# am_spp_cells <- get_am_spp_cells(occurcells_cut = 0, prob_cut = 0)
am_spp_cells <- get_am_spp_cells(occurcells_cut = 10, prob_cut = 0.50)
### this is the IUCN spp mapped to HCAF:
iucn_spp_cells <- data.table::fread(here_anx('iucn_spp', 'iucn_spp_hcaf.csv'))

```


```{r process higher order taxa}

process_higher_taxa <- function(i, tx_high) {
  ### i <- 1
  ### i <- which(tx_high$taxonkey == 590107)
  tx_id <- tx_high$taxonkey[i]
  tx_nm <- tx_high$worms_name[i]
  
  tx_map_fstem <- here_anx('stressors/fishing', 
                           '1_total_catch_by_tx_cell/tx_catch_%s_%s.csv')
  # unlink(list.files(dirname(tx_map_fstem), full.names = TRUE))
  tx_map_f <- sprintf(tx_map_fstem, tx_id, tx_nm)
  
  if(!file.exists(tx_map_f)) {
    message('Processing ', basename(tx_map_f), '...')
    spp_in_taxon <- watson_maps_cleaned_df %>%
      filter(taxonkey == tx_id) %>%
      select(am_sid, iucn_sid, source) %>%
      distinct()
    
    tx_spp_rich <- map_tx_spp_rich(spp_in_taxon, am_spp_cells = am_spp_cells, 
                                   iucn_spp_cells = iucn_spp_cells)
  
    tx_catch <- map_tx_catch(tx_id = tx_id, catch_df = w_catch_df)
    tx_catch_total <- tx_catch %>%
      summarize(tot_catch = sum(pel_tot_catch + ben_tot_catch)) %>%
      .$tot_catch %>% round(2)
    
    tx_map_out <- inner_join(tx_spp_rich, tx_catch, by = c('loiczid' = 'cell'))
    
    if(nrow(tx_map_out) == 0) {
      if(nrow(tx_spp_rich > 0) & nrow(tx_catch > 0)) {
        message('  ... no observed overlap of catch and species range for ', tx_id, ': ', tx_nm,
                '\n      this drops ', tx_catch_total, ' tonnes of catch...')
      }
      tx_map_out <- data.frame(loiczid = -1, n_spp = NA,
                               pel_tot_catch = 0, ben_tot_catch = 0)
    }
    
    write_csv(tx_map_out, tx_map_f)
  } else {
    # message('File ', basename(tx_map_f), ' already exists... skipping!')
  }
}

tx_high <- watson_worms_tx_df %>%
  filter(tax_level < 6)

tmp <- parallel::mclapply(1:nrow(tx_high), mc.cores = 12,
                          FUN = process_higher_taxa, 
                          tx_high = tx_high)

```


## Species-level catch maps

Here, for each species in AquaMaps and IUCN, total up the catch associated with that species at the species level and at higher taxonomic levels, per LOICZID cell.  Write out as .csv.

Note, due to name mismatches and synonyms between AquaMaps, IUCN, and WoRMS, some species are listed across multiple species IDs.

Helper functions:

* `build_spp_catch_map()`: generate catch map across potentially multiple `taxonkey` values.
    * First collect higher-taxon-level catch per cell, dividing that by the number of similar species per cell, and assigning that value to the species
    * Then collect the species-specific catch
    * All catch values are summed and assigned to each cell
    * Result is saved out to Mazu for each species.  
        * Note, saved just by species name, not ID because multiple `am_sid` values map to a single species (e.g., for subspecies or synonyms)

```{r moar helper functions}

build_spp_catch_map <- function(tx_ids, tx_nms) {
  hi_taxa_ids <- tx_ids[tx_ids < 600000]
  hi_taxa_nms <- tx_nms[tx_ids < 600000]
  
  if(length(hi_taxa_ids) > 0) {
    fs <- here_anx('stressors/fishing/1_total_catch_by_tx_cell/tx_catch_%s_%s.csv') %>%
      sprintf(hi_taxa_ids, hi_taxa_nms)
    
    taxa_catch <- lapply(fs, read_csv, show_col_types = FALSE) %>%
      setNames(hi_taxa_ids) %>%
      bind_rows(.id = 'taxonkey') %>%
      mutate(pel_assigned_catch = pel_tot_catch / n_spp,
             ben_assigned_catch = ben_tot_catch / n_spp) %>%
      group_by(loiczid) %>%
      summarize(pel_tot_catch = sum(pel_assigned_catch),
                ben_tot_catch = sum(ben_assigned_catch))
  } else {
    taxa_catch = data.frame() ### empty dataframe as placeholder
  }
  
  spp_ids <- tx_ids[tx_ids >= 600000]
  if(length(spp_ids) == 0) {
    message('  No species-level taxonkey found... returning catch from higher taxa')
    return(taxa_catch)
  } 
  
  spp_catch <- map_tx_catch(tx_id = spp_ids, catch_df = w_catch_df) %>%
    rename(loiczid = cell)
  
  tot_catch_df <- bind_rows(taxa_catch, spp_catch) %>%
    group_by(loiczid) %>%
    summarize(pel_tot_catch = sum(pel_tot_catch),
              ben_tot_catch = sum(ben_tot_catch))
  
  return(tot_catch_df)
}
```


```{r process species level catch}

process_species_catch <- function(s, spp_vec, spp_map_fstem, source = 'aquamaps') {
  # s <- 'gadus macrocephalus' ### multiple taxonkey at spp level
  # s <- 'platybelone argalus' ### multiple am_sid
  # s <- 'lepas anatifera' ### file not being created
  # s <- am_spp_vec[1]
  i <- which(s == spp_vec)
  
  spp_map_f <- sprintf(spp_map_fstem, str_replace_all(s, ' +', '_'))
  
  if(!file.exists(spp_map_f)) {
    
    message('Processing species-total catch map for ', s, 
            ' (', i, ' of ', length(spp_vec), ')')
  
    s_df <- watson_maps_cleaned_df %>%
      filter(spp == s)
    
    spp_ids <- s_df %>%
      select(am_sid, iucn_sid) %>%
      mutate(source = source) %>%
      distinct()
    
    spp_map <- map_tx_spp_rich(spp_ids, 
                               am_spp_cells = am_spp_cells, 
                               iucn_spp_cells = iucn_spp_cells) %>%
      select(-n_spp)
    
    tx_keys_df <- s_df %>%
      select(taxonkey, worms_name) %>%
      distinct()
    tx_ids <- tx_keys_df$taxonkey %>% unique()
    tx_nms <- tx_keys_df$worms_name
    catch_map <- build_spp_catch_map(tx_ids, tx_nms)
    
    spp_catch_map <- spp_map %>%
      inner_join(catch_map, by = 'loiczid')
    
    tot_catch <- spp_catch_map %>%
      summarize(tot_catch = sum(pel_tot_catch + ben_tot_catch)) %>%
      .$tot_catch %>% round(2)
    
    # raster::plot(map_to_hcaf(spp_catch_map, which = 'pel_tot_catch'))
    
    message('  Found ', nrow(spp_catch_map), ' catch/presence cells for ', s, 
            ' totalling ', tot_catch, ' tonnes...')
    if(nrow(spp_catch_map) == 0) {
      spp_catch_map <- data.frame(loiczid = -1, pel_tot_catch = 0, ben_tot_catch = 0)
    }
    
    write_csv(spp_catch_map, spp_map_f)
    
  } else {
    # message('File ', basename(spp_map_f), ' exists... skipping!')
  }
}
```

``` {r iterate over AquaMaps species IDs}

am_spp_vec <- read_csv(here('_setup/stressors/int/watson_maps_lookup.csv')) %>%
  filter(source == 'aquamaps') %>%
  .$spp %>% 
  unique() %>% sort()
    ### 17392 spp

am_spp_map_fstem <- here_anx('stressors/fishing/2_total_catch_by_spp_cell',
                          'am_spp_catch_%s.csv')

x <- list.files(dirname(am_spp_map_fstem), pattern = 'am_spp_catch', full.names = TRUE)
### unlink(x)

# x <- list.files(dirname(am_spp_map_fstem), full.names = TRUE)
# drop <- data.frame(f = x, y = file.size(x)) %>% filter(y < 100) %>% .$f
### unlink(drop)

### don't rerun species already done...
spp_with_files <- basename(x) %>% 
  str_remove_all('am_spp_catch_|.csv') %>% 
  str_replace_all('_', ' ')

am_spp_vec <- am_spp_vec[!am_spp_vec %in% spp_with_files]

if(length(am_spp_vec) > 0) {
  tmp <- parallel::mclapply(am_spp_vec, mc.cores = 12,
                            FUN = process_species_catch, 
                            spp_vec = am_spp_vec,
                            spp_map_fstem = am_spp_map_fstem)
}
```

``` {r iterate over IUCN species}
### While we prioritized AquaMaps over IUCN, here let's just run all the 
### available IUCN species in case we change our priority later...
iucn_spp_vec <- read_csv(here('_setup/stressors/int/watson_maps_lookup.csv')) %>%
  filter(!is.na(iucn_sid)) %>%
  .$spp %>% 
  unique() %>% sort()
    ### 4744 spp

iucn_spp_map_fstem <- here_anx('stressors/fishing/2_total_catch_by_spp_cell',
                          'iucn_spp_catch_%s.csv')

x <- list.files(dirname(iucn_spp_map_fstem), pattern = 'iucn_spp_catch',
                full.names = TRUE)
### unlink(x)

spp_with_files <- basename(x) %>% 
  str_remove_all('iucn_spp_catch_|.csv') %>% 
  str_replace_all('_', ' ')

iucn_spp_vec <- iucn_spp_vec[!iucn_spp_vec %in% spp_with_files]

if(length(iucn_spp_vec) > 0) {
  tmp <- parallel::mclapply(iucn_spp_vec, mc.cores = 12,
                            FUN = process_species_catch, 
                            spp_vec = iucn_spp_vec,
                            spp_map_fstem = iucn_spp_map_fstem,
                            source = 'iucn')
}

```

```{r check results, eval = FALSE, include = FALSE}
x <- list.files(dirname(spp_map_fstem), full.names = TRUE)

### unlink zero-length files if necessary to reprocess
# df <- data.frame(x, fsize = file.size(x))
# y <- df %>% filter(fsize < 100) %>% .$x
# unlink(y)

spp_with_files <- basename(x) %>% 
  str_remove_all('^am_|^iucn_|spp_catch_|.csv') %>% 
  str_replace_all('_', ' ')

spp_wo_files <- spp_vec[!spp_vec %in% spp_with_files]
head(spp_wo_files)
```

