---
title: 'Set up IUCN marine species list and risk assessments'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/src/templates/ohara_hdr.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'figs/',
                      echo = TRUE, message = FALSE, warning = FALSE)

library(oharac) ### remotes::install_github('oharac/oharac')
  ### includes some helper functions, e.g., dt_join
library(tidyverse)
library(here)

source(here('common_fxns.R'))
source('iucn_api_fxns.R') ### in same folder

```

# Summary

Get IUCN current risk assessments and historical assessments over time, for all IUCN marine species.

# Data Sources

### IUCN Red List

# Methods

## Get IUCN historical assessments for all available IUCN marine spp

### Get info on all species

Using the `mc_get_from_api()` function, get the entire species list of IUCN Red List assessed species.  This includes both terrestrial and marine species.

``` {r get_spp_info_from_api}
### Get all pages and bind into total species list.  This is pretty fast.

spp_info_from_api_file <- here_anx('iucn_spp', 
                                   sprintf('spp_info_from_api_%s.csv', api_version))
reload <- FALSE

if(!file.exists(spp_info_from_api_file) | reload) {
  
  message('Using API to create full species list from scratch')
  
  spp_npage_url <- sprintf('http://apiv3.iucnredlist.org/api/v3/speciescount?token=%s', 
                           api_key)
  n_spp <- fromJSON(spp_npage_url) %>%
    .$count %>% as.integer()
  n_pages <- ceiling(n_spp/10000)
  
  spp_page_url <- 'http://apiv3.iucnredlist.org/api/v3/species/page/%s?token=%s'
  spp_df_all <- mc_get_from_api(spp_page_url, c(0:(n_pages - 1)), api_key, delay = 1)

  spp_df_all <- spp_df_all %>%
    dplyr::select(-infra_rank, -infra_name, -count, -page) %>%
    rename(iucn_sid = taxonid, sciname = scientific_name) %>%
    setNames(names(.) %>%
               str_replace('_name', ''))
  
  message('Full list length: ', nrow(spp_df_all), '; unique species IDs: ', 
          length(spp_df_all$iucn_sid %>% unique()))
  write_csv(spp_df_all, spp_info_from_api_file)
  
} else {
  
  message('File of API species list exists: \n  ', spp_info_from_api_file)

}

# spp_df_all <- read_csv(spp_info_from_api_file)
```

### Determine marine species using habitat information

#### Get species habitat info for all species from IUCN API

From the full IUCN species list, send each IUCN species ID into the API to get the habitats listed for that species.  Combine all habitat dataframes into a master dataframe of all habitats for all species.  Note that many species do not have habitat information and will be listed as NA for habitat variables.

``` {r determine_spp_habs}
### For each species ID on the total list, get a dataframe of habitats.
### This is slow.  Skip if possible.

spp_habs_from_api_file <- here_anx('iucn_spp', 
                                   sprintf('spp_habs_from_api_%s.csv', api_version))
reload <- FALSE

if(!file.exists(spp_habs_from_api_file) | reload) {
  
  message('Using API to determine species habitats from full species info list')
  
  spp_ids_all <- read_csv(spp_info_from_api_file) %>%
    .$iucn_sid
  
  spp_habs_url <- 'http://apiv3.iucnredlist.org/api/v3/habitats/species/id/%s?token=%s'
  
  ### Breaking this into chunks...
  ### 500 spp takes 184 seconds; at that rate, 87851 species should take 
  ###   about 9 hrs.  Each chunk will save to tmp for later combining.

  chunk_size <- 500
  n_chunks <- ceiling(length(spp_ids_all)/chunk_size)
  
  if(!dir.exists(here_anx('iucn_spp', 'tmp'))) {
    dir.create(here_anx('iucn_spp', 'tmp'))
  }
  
  for(j in 1:n_chunks) { 
    ### j <- 2
    spp_index <- c( ((j - 1) * chunk_size + 1) : min((j * chunk_size), length(spp_ids_all)) )
    chunk_file <- here_anx('iucn_spp', 'tmp', 
                            sprintf('spp_habs_chunk_%s_%s_%s.csv', 
                            min(spp_index), max(spp_index), api_version))

    if(!file.exists(chunk_file)) {
      message('Getting habitat info for species ', min(spp_index), ' to ', max(spp_index))
      
      spp_ids_chunk <- spp_ids_all[spp_index]
      # system.time({
      spp_habs_chunk <- mc_get_from_api(spp_habs_url, spp_ids_chunk, api_key, 
                                        cores = 12, delay = 1, verbose = FALSE)
      # })
      message('... found ', nrow(spp_habs_chunk), ' habitat rows for these species')
      
      write_csv(spp_habs_chunk, chunk_file)
      
    } else {
      
      message('Chunk file ', chunk_file, ' already exists; skipping these spp')
      
    }
  }
  
  ### fields: 
  ### id | code | habitat | suitability | season | majorimportance

  spp_hab_chunk_files <- list.files(here_anx('iucn_spp', 'tmp'), 
                                    pattern = 'spp_habs_chunk', 
                                    full.names = TRUE)
  
  spp_habs_df <- lapply(spp_hab_chunk_files, FUN = function(x) {
    read.csv(x) %>%
      mutate(code = as.character(code))}) %>%
    bind_rows() %>%
    rename(iucn_sid = id) %>%
    mutate(iucn_sid = ifelse(is.na(iucn_sid), param_id, iucn_sid)) %>%
    arrange(iucn_sid)
  
  spp_errors <- spp_habs_df %>%
    filter(!is.na(api_error) & api_error != 'no data.frame') %>%
    .$iucn_sid
  ### all these errors are due to returning a zero-length list instead of a data.frame

  write_csv(spp_habs_df, spp_habs_from_api_file)
  
} else {
  
  message('File of species habitats from API exists: \n  ', spp_habs_from_api_file)

}

```

```{r check habs file}
habs <- read_csv(spp_habs_from_api_file) %>%
  filter(str_detect(api_error, 'try-error'))
if(nrow(habs) > 0) stop('Some habitat queries resulted in a try-error')

```

``` {r determine_spp_systems}
### For each species ID on the total list, get species information, which
### includes "system" of marine, terrestrial, or both.

spp_sys_from_api_file <- here_anx('iucn_spp', 
  sprintf('spp_systems_from_api_%s.csv', api_version))
reload <- FALSE

if(!file.exists(spp_sys_from_api_file) | reload) {
  
  message('Using API to determine species systems from full species info list')
  
  spp_ids_all <- read_csv(spp_info_from_api_file) %>%
    .$iucn_sid
  
  spp_systems_url <- 'http://apiv3.iucnredlist.org/api/v3/species/id/%s?token=%s'

  chunk_size <- 2000
  n_chunks <- ceiling(length(spp_ids_all)/chunk_size)
  
  if(!dir.exists(here_anx('iucn_spp', 'tmp'))) {
    dir.create(here_anx('iucn_spp', 'tmp'))
  }
  
  for(j in 1:n_chunks) { 
    ### j <- 1
    spp_index <- c( ((j - 1) * chunk_size + 1) : min((j * chunk_size), length(spp_ids_all)) )
    chunk_file <- here_anx('iucn_spp', 'tmp', 
                    sprintf('spp_sys_chunk_%s_%s.csv', 
                            min(spp_index), max(spp_index)))

    if(!file.exists(chunk_file) | reload) {
      message('Getting systems info for species ', min(spp_index), ' to ', max(spp_index))
      
      spp_ids_chunk <- spp_ids_all[spp_index]
      spp_sys_chunk <- mc_get_from_api(spp_systems_url, spp_ids_chunk, api_key, 
                                       cores = 12, delay = 1, verbose = FALSE)

      spp_sys_chunk <- spp_sys_chunk %>%
        select(iucn_sid = name, 
               sciname = scientific_name, comname = main_common_name,
               contains('system'), year = published_year, category, criteria)
      message('... found ', nrow(spp_sys_chunk), ' systems for these species')
      
      write_csv(spp_sys_chunk, chunk_file)
      
    } else {
      
      message('Chunk file ', chunk_file, ' already exists; skipping these spp')
      
    }
  }
  
  ### fields: 
  ### id | code | habitat | suitability | season | majorimportance

  spp_sys_chunk_files <- list.files(here_anx('iucn_spp', 'tmp'), 
                                    pattern = 'spp_sys_chunk', 
                                    full.names = TRUE)
  
  spp_sys_df <- lapply(spp_sys_chunk_files, FUN = function(x) {
      read.csv(x)
    }) %>%
    bind_rows() %>%
    arrange(iucn_sid)
  
  write_csv(spp_sys_df, spp_sys_from_api_file)
  
} else {
  
  message('File of species systems from API exists: \n  ', spp_sys_from_api_file)

}


```

```{r check systems file}
systems <- read_csv(spp_sys_from_api_file)
if('api_error' %in% names(systems)) {
  systems <- systems %>%
    filter(str_detect(api_error, 'try-error'))
  if(nrow(systems) > 0) stop('Some system queries resulted in a try-error')
}
```

#### Generate Habitat inclusion list

From the habitats gleaned in the previous chunk, generate an inclusion list based on those that are considered marine.  "Included" habitats are determined from inspection of the habitat list; we are including habitats 9-12, plus 15.11, 15.12, 15.13.  Note category 13 is Marine Coastal/Supratidal, but includes many species whose "marine" dependence is only incidental.  If these species do not show up in category 12 (marine intertidal) then they are assumed to not actually depend on marine habitats.

``` {r generate_hab_inclusion_list, eval = TRUE}

hab_inclusion_file <- file.path(dir_setup, 'int', 'iucn_habitat_categories.csv')

hab_cats <- read_csv(spp_habs_from_api_file, col_types = 'iccccc__') %>%
  select(habitat, code) %>%
  distinct() %>%
  separate(code, c('cat', 'subcat1', 'subcat2'),
           remove = FALSE, convert = TRUE) %>%
  arrange(cat, subcat1, subcat2) %>%
  mutate(include = ifelse(cat %in% c(9:12), TRUE, FALSE),
         include = ifelse(cat == 15 & subcat1 %in% c(11, 12, 13), TRUE, include),
         include = ifelse(cat == 13 & subcat1 == 1, TRUE, include),
           ### Category 13 (Marine coastal/supratidal excluded here: except for
           ### sea cliffs and offshore islands (13.1))
         include = ifelse(cat %in% 17:18, TRUE, include)) %>%
           ### 17 and 18 are "other" and "unknown"; "unknown" includes some
           ### marine spp e.g. 170022 and 170033, slipper lobsters; "other"
           ### also includes marine spp e.g. 60087 sepia stingray
  filter(!is.na(code))

### Note these "include" values were manually determined by inspecting the habitat categories
### Notes on categories related to depth clipping 
### see also: http://www.iucnredlist.org/technical-documents/classification-schemes/habitats-classification-scheme-ver3
### * category 9 is neritic (shallow) though 9.1 is specifically pelagic (NOT shallow)
### * category 10 is oceanic at different depths (pelagic: NOT shallow)
### * category 11 is Marine Deep Ocean Floor (Benthic and Demersal) (NOT shallow)
### * category 12 is Marine Intertidal (shallow)
### * category 13 is Marine Coastal/Supratidal (shallow) 
### * category 15 includes shallow structures
### So: for depth clipping, cut at 200 m for all but category 9.1, 10, 11

write_csv(hab_cats, hab_inclusion_file)

```

#### Determine marine species by habitat and system

Marine species depth classifications:

* 0-20? m: organisms classified as intertidal (category 12) and shallower
* 0-200 m: organisms classified as neritic (category 9) and shallower
* 200+ m: organisms in marine oceanic (category 10) and deep benthic (category 11)
* deep oceanic: organisms ONLY in 10.3, 10.4 (pelagic below 1000 m), or 11 (deep benthic).

It appears that coastal species suffer from the extended buffers so clipping these to a 200 m bathymetry line is important.  Intertidal organisms may benefit from further clipping to shallower depths, depending on the quality of bathymetric layers.

``` {r combine hab and system}

spp_habs_from_api <- read_csv(spp_habs_from_api_file,
                              col_types = cols(.default = 'c', iucn_sid = 'i'))
### 'code' is character since it is in the form x.xx.xxx

spp_systems_from_api <- read_csv(spp_sys_from_api_file) %>%
  select(iucn_sid, sciname, comname, 
         marine_system, terrestrial_system, freshwater_system) %>%
  distinct()

### using inner_join, use marine hab lookup to attach to the full spp habitat
### list, adding more info and filtering to just marine habitats or marine systems
hab_marine <- read_csv(hab_inclusion_file)

spp_habs_and_systems <- spp_habs_from_api %>%
  left_join(spp_systems_from_api, by = 'iucn_sid') %>%
  left_join(hab_marine, by = c('habitat', 'code'))

### Spot checks:  how to best differentiate true marine spp?
# qwer <- spp_habs_and_systems %>%
#   filter(include == TRUE)
# length(qwer$iucn_sid %>% unique())
# length(qwer %>% filter(!cat %in% 17:18) %>% .$iucn_sid %>% unique())
### 19517 spp marine by habitat only (NAs dropped); note undoubtedly
### some "other" and "unknown" that are NOT marine - only 16069 when
### excluding "other" and "unknown"

# asdf <- spp_habs_and_systems %>%
#   filter(marine_system) %>%
#   distinct()
# length(asdf$iucn_sid %>% unique())
### 16304 spp by marine_system only; some might be marine/terrestrial

# zxcv <- spp_habs_and_systems %>%
#   filter(include == TRUE | (is.na(include) & marine_system == TRUE)) %>%
#   distinct()
# length(zxcv$iucn_sid %>% unique())
# length(zxcv %>% filter(!cat %in% 17:18) %>% .$iucn_sid %>% unique())
### 19788 in marine habitats, and/or with NA habitat but marine_system
### 16340 when ignoring "other" and "unknown"

# qwer <- spp_habs_and_systems %>%
#   filter((include == TRUE | is.na(include)) & marine_system == TRUE)
# length(qwer$iucn_sid %>% unique())
### 16039 both marine hab (or NA hab) AND marine_system

### Let's examine the spp that are marine_system but not by hab,
### and by hab but not marine_system.
# asdf <- spp_habs_and_systems %>%
#   filter(include == TRUE & !marine_system)
# length(asdf$iucn_sid %>% unique())
# length(asdf %>% filter(!cat %in% 17:18) %>% .$iucn_sid %>% unique())
### 3749 spp: including "other" and "unknown" requires an additional filter... just
### too many extras included here.  904 if we ignore those.
# zxcv <- spp_habs_and_systems %>%
#   group_by(iucn_sid) %>%
#   mutate(include = any(include == TRUE)) %>%
#   filter(include == FALSE & marine_system)
# length(zxcv$iucn_sid %>% unique())
### 265 spp here.  This looks pretty solid - the remainders look like
### they are inland wetlands, coastal lakes, caves, etc.  Some may
### be misclassified by IUCN as to their habitats.
```

Filter the full set by marine habitats (`include == TRUE`), marine system (`marine_system == TRUE`), and seabird (cut all Aves not on seabird list)
``` {r filter by hab system and seabird}

### Get the BLI list of seabirds; include only these regardless of hab or system
seabirds_from_bli <- read_csv(here('_raw/seabird_species_2019.csv')) %>%
  rename(sciname = scientific)

birds_marine <- read_csv(spp_info_from_api_file) %>%
  filter(class == 'AVES') %>%
  select(iucn_sid, sciname) %>%
  left_join(seabirds_from_bli, by = 'sciname')
birds_exclude <- birds_marine %>%
  filter(is.na(seabird_all))

spp_marine <- spp_habs_and_systems %>%
  filter((include == TRUE | is.na(include)) & marine_system == TRUE) %>%
  filter(!iucn_sid %in% birds_exclude$iucn_sid)
# length(spp_marine$iucn_sid %>% unique())
### These 15613 spp either are positively coded hab or NA hab, and
### ALSO classified as marine system.  This is a reasonably aggressive
### cut that seems to minimize false positives and false negatives.
### NOTE: This still includes hippos because of estuaries - see next cut.

### See which species are only "marginal" or of unknown suitability for
### marine habitats.  Filter out those that are pelagic, subtidal - 
### those are clearly marine species.  If spp are only found in
### intertidal as a marginal habitat, inspect them - perhaps they're
### terrestrial that venture into intertidal occasionally... should they be included?
marg_suit <- spp_marine %>%
  group_by(iucn_sid) %>%
  filter(include == TRUE) %>%
  arrange(suitability) %>%
  summarize(suit_all = tolower(paste0(unique(suitability), collapse = ', ')),
            intertidal_only = sum(!cat %in% c(12) & !(cat == 9 & subcat1 == 10)) == 0) %>%
              ### cat 9.10 is estuaries - if only intertidal or estuaries, 
              ### check for suitability
  filter(!str_detect(suit_all, 'suitable|unknown|^na')) %>%
  filter(intertidal_only) %>%
  left_join(read_csv(spp_info_from_api_file), by = 'iucn_sid') %>%
  select(iucn_sid, sciname, suit_all, kingdom, phylum, class, order, family)

### 4 spp; before bird filter, there were 20
write_csv(marg_suit, 
          here('_setup/int', sprintf('spp_marine_marginal_%s.csv', api_version)))
  
### Trim down to just the species ID, a quick list of habitats, and whether
### the species should be considered to be OK for deeper waters (200 m +)
spp_habs_clean <- spp_marine %>%
  filter(!iucn_sid %in% marg_suit$iucn_sid) %>%
  group_by(iucn_sid) %>%
  summarize(habs = paste0(code, collapse = ', '),
            max_depth = case_when(all((cat == 10 & subcat1 %in% 3:4) |
                                        cat == 11)        ~ 'deep oceanic',
                                  any(cat %in% c(10, 11)) ~ '200 m +',
                                  any(cat %in% c(9, 15))  ~ '< 200 m',
                                  any(cat %in% c(12))     ~ '< 20 m',
                                  TRUE                    ~ 'unknown'))

write_csv(spp_habs_clean, 
          here('_data/iucn_spp', sprintf('spp_marine_from_api_%s.csv', api_version)))

spp_habs_clean$iucn_sid %>% n_distinct()
### 15609 total marine species
```
  
-----

``` {r get_iucn_past_assessments, eval = FALSE}

spp_timeseries_file <- here('_data/iucn_spp', 
                            sprintf('iucn_risk_timeseries_%s.csv', api_version))

iucn_spp_info <- read_csv(here_anx('iucn_spp', 
                                   sprintf('spp_info_from_api_%s.csv', api_version)))

iucn_marine_spp <- read_csv(here('_data/iucn_spp', 
                                 sprintf('spp_marine_from_api_%s.csv', api_version))) %>%
  left_join(iucn_spp_info)
### Subpopulations are in here too, by ID number

reload <- FALSE

if(!file.exists(spp_timeseries_file) | reload) {

  spp_hist_url <- 'http://apiv3.iucnredlist.org/api/v3/species/history/id/%s?token=%s'
  
  sid_list <- iucn_marine_spp %>%
    .$iucn_sid %>%
    unique() %>%
    sort()
    
  chunk_size <- 500
  n_chunks <- ceiling(length(sid_list)/chunk_size)
  
  for(j in 1:n_chunks) { 
    ### j <- 1
    spp_index <- c( ((j - 1) * chunk_size + 1) : min((j * chunk_size), length(sid_list)) )
    chunk_file <- here_anx('iucn_spp', 'tmp', 
                            sprintf('spp_past_assess_chunk_%s_%s.csv', 
                            min(spp_index), max(spp_index)))

    if(!file.exists(chunk_file)) {
      message('Getting past assessment info for species ', min(spp_index), ' to ', max(spp_index))
      
      spp_ids_chunk <- sid_list[spp_index]
      spp_past_chunk <- mc_get_from_api(spp_hist_url, spp_ids_chunk, api_key, 
                                        delay = 1, cores = 12, verbose = FALSE)
      message('... found ', nrow(spp_past_chunk), ' past assessment rows for these species')
      
      write_csv(spp_past_chunk, chunk_file)
      
    } else {
      
      message('Chunk file ', chunk_file, ' already exists; skipping these spp')
      
    }
  }
  
  spp_past_chunk_files <- list.files(here_anx('iucn_spp', 'tmp'), 
                                     pattern = 'spp_past_assess_chunk', 
                                     full.names = TRUE)
  
  spp_past_df <- lapply(spp_past_chunk_files, FUN = function(x) {
    read_csv(x) %>%
      mutate(code = as.character(code))}) %>%
    bind_rows() %>%
    rename(iucn_sid = name) %>%
    mutate(iucn_sid = ifelse(is.na(iucn_sid), param_id, iucn_sid)) %>%
    arrange(iucn_sid)
  
  ### Clean up the time series: reclassify old codes to current
  cat_lookup <- read_csv(file.path(dir_setup, 'raw', 'risk_code_lookup.csv'))
  
  spp_past_df1 <- spp_past_df %>%
    left_join(cat_lookup, by = c('code', 'category')) %>%
    rename(old_cat  = code,
           cat_txt  = category,
           cat_ts   = code_current)
  
  pop_cat <- data.frame(cat_ts       = c("LC", "NT", "VU", "EN", "CR", "EX", "NE", "DD"), 
                        cat_ts_score = c( 0.0,  0.2,  0.4,  0.6,  0.8,  1.0,  NA,   NA))
    
  spp_past_df1 <- spp_past_df1 %>% 
    left_join(pop_cat, by = 'cat_ts') %>%
    filter(!is.na(cat_ts_score) & !is.na(year)) %>%
    arrange(iucn_sid, year) %>%
    select(iucn_sid, year, cat_ts, cat_ts_score) %>%
    mutate(iucn_version = api_version)
  
  write_csv(spp_past_df1, spp_timeseries_file)
  
} else {
  
}

```

``` {r get_iucn_current_assessment}

spp_curr_file <- here('_data/iucn_spp', 
                      sprintf('iucn_risk_current_%s.csv', api_version))
iucn_spp_info <- read_csv(here_anx('iucn_spp', 'iucn',
                                   sprintf('spp_info_from_api_%s.csv', api_version)))

iucn_marine_spp <- read_csv(here('_data/iucn_spp', 
                                 sprintf('spp_marine_from_api_%s.csv', api_version))) %>%
  left_join(iucn_spp_info)

reload <- FALSE

if(!file.exists(spp_curr_file) | reload) {

  spp_curr_url <- 'http://apiv3.iucnredlist.org/api/v3/species/id/%s?token=%s'
  
  sid_list <- iucn_marine_spp %>%
    .$iucn_sid %>%
    unique() %>%
    sort()
  
  chunk_size <- 500
  n_chunks <- ceiling(length(sid_list)/chunk_size)
  
  if(!dir.exists(here_anx('iucn_spp', 'tmp'))) {
    dir.create(here_anx('iucn_spp', 'tmp'))
  }
  
  for(j in 1:n_chunks) { 
    ### j <- 1
    spp_index <- c( ((j - 1) * chunk_size + 1) : min((j * chunk_size), length(sid_list)) )
    chunk_file <- here_anx('iucn_spp', 'tmp', 
                           sprintf('spp_curr_chunk_%s_%s.csv', 
                                   min(spp_index), max(spp_index)))

    if(!file.exists(chunk_file) | reload) {
      message('Getting current assessment info for species ', min(spp_index), ' to ', max(spp_index))
      
      spp_ids_chunk <- sid_list[spp_index]
      system.time({
      spp_curr_chunk <- mc_get_from_api(spp_curr_url, spp_ids_chunk, api_key, 
                                        cores = 12, delay = 1, verbose = FALSE)
      })
      message('... found ', nrow(spp_curr_chunk), ' current assessments for these species')
      
      write_csv(spp_curr_chunk, chunk_file)
      
    } else {
      
      message('Chunk file ', chunk_file, ' already exists; skipping these spp')
      
    }
  }

  spp_curr_chunk_files <- list.files(here_anx('iucn_spp', 'tmp'), 
                                     pattern = 'spp_curr_chunk', 
                                     full.names = TRUE)
  
  spp_current_df <- lapply(spp_curr_chunk_files, FUN = function(x) {
      read_csv(x, col_types = cols(.default = 'c'))
    }) %>%
    bind_rows()
  
  spp_current_df1 <- spp_current_df %>%
    transmute(iucn_sid = as.integer(name),
              sciname = scientific_name,
              comname = main_common_name, 
              pub_year = as.integer(published_year), 
              code = category, 
              depth_upper = as.integer(depth_upper), 
              depth_lower = as.integer(depth_lower),
              elev_upper = as.integer(elevation_upper), 
              elev_lower = as.integer(elevation_lower),
              aoo_km2 = as.integer(aoo_km2), 
              eoo_km2 = as.integer(eoo_km2),
              criteria)
  ### dropping columns: 
  # kingdom, phylum, class, order, family, genus, 
  # authority, marine_system, freshwater_system, terrestrial_system, 
  # assessor, reviewer, errata_flag, errata_reason, amended_flag, amended_reason
  ### keeping all listings regardless of NE or DD

  ### Note that the system info is available here as well... should I just do this
  ### function instead of the system function?
  
  ### Clean up the time series: reclassify old codes to current and add scores
  cat_lookup <- read_csv(here('_raw', 'risk_code_lookup.csv')) %>%
    select(-category)
  
  spp_current_df2 <- spp_current_df1 %>%
    left_join(cat_lookup, by = c('code')) %>%
    rename(old_cat  = code,
           cat      = code_current) %>%
    mutate(iucn_sid = as.integer(iucn_sid)) %>%
    arrange(iucn_sid) %>%
    mutate(iucn_version = api_version)
  
  write_csv(spp_current_df2, spp_curr_file)
  
}

```
